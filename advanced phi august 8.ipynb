{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOuo65vSfLs5kTjLHTmzHdt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"BsAMGh8Z8EP_","executionInfo":{"status":"ok","timestamp":1754677782395,"user_tz":240,"elapsed":6131,"user":{"displayName":"Kate Huneke","userId":"12242479504218415499"}}},"outputs":[],"source":["\"\"\"\n","Advanced Pattern Evolution Predictor\n","=====================================\n","Integrates window-729 phase detection, autocorrelation structure,\n","Feigenbaum transitions, and chaos-to-order evolution tracking.\n","\"\"\"\n","\n","import numpy as np\n","import pandas as pd\n","from scipy import stats, signal\n","from sklearn.ensemble import RandomForestClassifier\n","from typing import Dict, List, Tuple, Optional\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","class AdvancedPatternPredictor:\n","    \"\"\"\n","    Sophisticated pattern predictor that tracks evolution and phase transitions.\n","    \"\"\"\n","\n","    def __init__(self):\n","        # Key constants discovered\n","        self.PHI = 1.618033988749895\n","        self.INV_PHI_SQUARED = 0.381966011250105\n","        self.FEIGENBAUM = 4.669201609\n","        self.CRITICAL_NUMBER = 0.00234376636\n","        self.FINE_STRUCTURE = 137.035999\n","\n","        # Key windows and lags\n","        self.PHASE_WINDOW = 729\n","        self.HARMONIC_WINDOW = 137\n","        self.KEY_LAGS = [42, 45]  # Discovered autocorrelation peaks\n","\n","        # Attractors to monitor\n","        self.ATTRACTORS = {\n","            'inv_phi_squared': 0.382,\n","            'phi_conjugate': 0.618,\n","            'unity': 1.0,\n","            'phi': 1.618,\n","            'double': 2.0,\n","            'half': 0.5,\n","            'critical': 0.48  # The discovered universal density\n","        }\n","\n","        # Phase states\n","        self.PHASE_CHAOS = 0\n","        self.PHASE_TRANSITION = 1\n","        self.PHASE_CONVERGING = 2\n","        self.PHASE_STABLE = 3\n","\n","    def analyze_complete(self, data: pd.DataFrame) -> Dict:\n","        \"\"\"\n","        Complete analysis integrating all discovered patterns.\n","        \"\"\"\n","        results = {\n","            'phase_evolution': self.track_phase_evolution(data),\n","            'autocorr_signals': self.leverage_autocorrelation(data),\n","            'feigenbaum_detection': self.detect_feigenbaum_transitions(data),\n","            'attractor_dynamics': self.analyze_attractor_dynamics(data),\n","            'trading_signals': self.generate_intelligent_signals(data),\n","            'chaos_metrics': self.measure_chaos_level(data)\n","        }\n","\n","        return results\n","\n","    def track_phase_evolution(self, data: pd.DataFrame) -> Dict:\n","        \"\"\"\n","        Use window-729 as phase detector to track system evolution.\n","        \"\"\"\n","        prices = data['Close'].values\n","\n","        # Calculate rolling 729-window density\n","        window = self.PHASE_WINDOW\n","        densities_729 = []\n","        timestamps = []\n","\n","        # Use smaller step for more granular tracking\n","        step = max(1, window // 10)  # 10% overlap for smooth evolution\n","\n","        for i in range(0, len(prices) - window, step):\n","            segment = prices[i:i+window]\n","            binary = (np.diff(segment) > 0).astype(int)\n","            density = np.mean(binary)\n","            densities_729.append(density)\n","            timestamps.append(i + window)\n","\n","        if len(densities_729) < 3:\n","            return {}\n","\n","        densities_729 = np.array(densities_729)\n","\n","        # Calculate rate of change (velocity)\n","        velocity = np.diff(densities_729)\n","\n","        # Calculate acceleration (second derivative)\n","        acceleration = np.diff(velocity) if len(velocity) > 1 else []\n","\n","        # Detect phase based on dynamics\n","        phases = []\n","        for i in range(len(densities_729)):\n","            phase = self._classify_phase(\n","                densities_729[i],\n","                velocity[min(i, len(velocity)-1)] if len(velocity) > 0 else 0,\n","                acceleration[min(i, len(acceleration)-1)] if len(acceleration) > 0 else 0\n","            )\n","            phases.append(phase)\n","\n","        # Find closest attractor for each point\n","        attractor_distances = []\n","        closest_attractors = []\n","\n","        for density in densities_729:\n","            distances = {name: abs(density - value)\n","                        for name, value in self.ATTRACTORS.items()\n","                        if 0 <= value <= 1}  # Only density-compatible attractors\n","\n","            closest = min(distances.items(), key=lambda x: x[1])\n","            closest_attractors.append(closest[0])\n","            attractor_distances.append(closest[1])\n","\n","        # Detect convergence patterns\n","        is_converging = self._detect_convergence(densities_729, attractor_distances)\n","\n","        # Calculate the \"mellowing\" metric (reduction in volatility over time)\n","        mellowing_score = self._calculate_mellowing(densities_729)\n","\n","        return {\n","            'densities_729': densities_729,\n","            'velocity': velocity,\n","            'acceleration': acceleration,\n","            'phases': phases,\n","            'closest_attractors': closest_attractors,\n","            'attractor_distances': attractor_distances,\n","            'is_converging': is_converging,\n","            'mellowing_score': mellowing_score,\n","            'current_phase': phases[-1] if phases else None,\n","            'current_density': densities_729[-1] if len(densities_729) > 0 else None,\n","            'trend': 'approaching' if is_converging else 'diverging'\n","        }\n","\n","    def leverage_autocorrelation(self, data: pd.DataFrame) -> Dict:\n","        \"\"\"\n","        Use discovered autocorrelation at lags 42, 45 for prediction.\n","        \"\"\"\n","        returns = data['returns'].dropna().values\n","\n","        if len(returns) < max(self.KEY_LAGS) + 10:\n","            return {}\n","\n","        signals = []\n","\n","        # For each point, look at the key lag relationships\n","        for i in range(max(self.KEY_LAGS), len(returns)):\n","            # Get returns at key lags\n","            lag_42_return = returns[i - 42] if i >= 42 else 0\n","            lag_45_return = returns[i - 45] if i >= 45 else 0\n","\n","            # The 3-period difference might create interference pattern\n","            interference = lag_42_return - lag_45_return\n","\n","            # Signal based on lag pattern\n","            if interference > 0.01:  # Constructive interference\n","                signal = 1\n","            elif interference < -0.01:  # Destructive interference\n","                signal = -1\n","            else:\n","                signal = 0\n","\n","            signals.append(signal)\n","\n","        # Calculate the autocorrelation strength at our key lags\n","        from statsmodels.tsa.stattools import acf\n","        acf_values = acf(returns, nlags=max(self.KEY_LAGS) + 5)\n","\n","        lag_42_strength = acf_values[42] if len(acf_values) > 42 else 0\n","        lag_45_strength = acf_values[45] if len(acf_values) > 45 else 0\n","\n","        return {\n","            'signals': signals,\n","            'lag_42_strength': lag_42_strength,\n","            'lag_45_strength': lag_45_strength,\n","            'interference_pattern': lag_42_strength - lag_45_strength,\n","            'signal_confidence': abs(lag_42_strength) + abs(lag_45_strength)\n","        }\n","\n","    def detect_feigenbaum_transitions(self, data: pd.DataFrame) -> Dict:\n","        \"\"\"\n","        Detect period-doubling cascades and Feigenbaum transitions.\n","        \"\"\"\n","        prices = data['Close'].values\n","\n","        if len(prices) < 200:\n","            return {}\n","\n","        # Look for period doubling in local extrema\n","        extrema_indices = signal.argrelextrema(prices, np.greater)[0]\n","\n","        if len(extrema_indices) < 10:\n","            return {}\n","\n","        # Calculate distances between extrema (periods)\n","        periods = np.diff(extrema_indices)\n","\n","        # Look for period doubling sequences\n","        doubling_ratios = []\n","        for i in range(1, len(periods)):\n","            if periods[i-1] > 0:\n","                ratio = periods[i] / periods[i-1]\n","                doubling_ratios.append(ratio)\n","\n","        if not doubling_ratios:\n","            return {}\n","\n","        # Check if ratios approach Feigenbaum constant\n","        doubling_ratios = np.array(doubling_ratios)\n","\n","        # The Feigenbaum constant appears in the limit of period-doubling\n","        # Look for sequences approaching 4.669...\n","        feigenbaum_distances = np.abs(doubling_ratios - self.FEIGENBAUM)\n","\n","        # Also check for \"inverted\" Feigenbaum (1/4.669 â‰ˆ 0.214)\n","        inverted_feigenbaum = 1 / self.FEIGENBAUM\n","        inverted_distances = np.abs(doubling_ratios - inverted_feigenbaum)\n","\n","        # Detect if we're in a period-doubling cascade\n","        is_cascade = np.any(feigenbaum_distances < 0.5) or np.any(inverted_distances < 0.1)\n","\n","        # Calculate the \"chaos parameter\" (how close to Feigenbaum)\n","        chaos_parameter = np.min(feigenbaum_distances) if len(feigenbaum_distances) > 0 else 1.0\n","\n","        # Check for the critical 0.00234... appearing in ratios\n","        critical_distances = np.abs(doubling_ratios - self.CRITICAL_NUMBER)\n","        has_critical_echo = np.any(critical_distances < 0.001)\n","\n","        return {\n","            'periods': periods,\n","            'doubling_ratios': doubling_ratios,\n","            'feigenbaum_distance': np.min(feigenbaum_distances) if len(feigenbaum_distances) > 0 else None,\n","            'inverted_distance': np.min(inverted_distances) if len(inverted_distances) > 0 else None,\n","            'is_cascade': is_cascade,\n","            'chaos_parameter': chaos_parameter,\n","            'has_critical_echo': has_critical_echo,\n","            'approaching_chaos': chaos_parameter < 0.5\n","        }\n","\n","    def analyze_attractor_dynamics(self, data: pd.DataFrame) -> Dict:\n","        \"\"\"\n","        Analyze how the system moves between attractors.\n","        \"\"\"\n","        prices = data['Close'].values\n","\n","        # Use multiple windows to detect multi-scale dynamics\n","        windows = [self.HARMONIC_WINDOW, self.PHASE_WINDOW, 89, 233]  # Include Fibonacci\n","\n","        attractor_strengths = {}\n","\n","        for window in windows:\n","            if len(prices) < window:\n","                continue\n","\n","            # Calculate density for this window\n","            binary = (np.diff(prices[-window:]) > 0).astype(int)\n","            density = np.mean(binary)\n","\n","            # Find closest attractor\n","            for name, value in self.ATTRACTORS.items():\n","                if 0 <= value <= 1:\n","                    distance = abs(density - value)\n","                    strength = np.exp(-distance * 10)  # Exponential decay of influence\n","\n","                    key = f'{name}_w{window}'\n","                    attractor_strengths[key] = strength\n","\n","        # Identify dominant attractor\n","        if attractor_strengths:\n","            dominant = max(attractor_strengths.items(), key=lambda x: x[1])\n","            dominant_name = dominant[0].split('_w')[0]\n","            dominant_strength = dominant[1]\n","        else:\n","            dominant_name = 'none'\n","            dominant_strength = 0\n","\n","        return {\n","            'attractor_strengths': attractor_strengths,\n","            'dominant_attractor': dominant_name,\n","            'dominant_strength': dominant_strength,\n","            'multi_attractor': len([s for s in attractor_strengths.values() if s > 0.5]) > 1\n","        }\n","\n","    def measure_chaos_level(self, data: pd.DataFrame) -> Dict:\n","        \"\"\"\n","        Measure the current chaos level in the system.\n","        \"\"\"\n","        returns = data['returns'].dropna().values\n","\n","        if len(returns) < 100:\n","            return {}\n","\n","        # 1. Lyapunov exponent approximation (using return divergence)\n","        lyapunov_approx = np.std(returns) / np.mean(np.abs(returns) + 1e-10)\n","\n","        # 2. Entropy\n","        hist, _ = np.histogram(returns, bins=50, density=True)\n","        hist = hist[hist > 0]\n","        shannon_entropy = -np.sum(hist * np.log2(hist + 1e-10)) / len(hist)\n","\n","        # 3. Fractal dimension (using box-counting approximation)\n","        prices = data['Close'].values\n","        if len(prices) > 100:\n","            # Simplified box-counting\n","            scales = [2, 4, 8, 16, 32]\n","            counts = []\n","            for scale in scales:\n","                scaled = prices[::scale]\n","                if len(scaled) > 1:\n","                    boxes = len(np.unique(np.round(scaled * scale)))\n","                    counts.append(boxes)\n","\n","            if len(counts) > 1:\n","                # Fractal dimension from slope\n","                log_scales = np.log(scales[:len(counts)])\n","                log_counts = np.log(counts)\n","                fractal_dim = -np.polyfit(log_scales, log_counts, 1)[0]\n","            else:\n","                fractal_dim = 1.5\n","        else:\n","            fractal_dim = 1.5\n","\n","        # Chaos score (0 = ordered, 1 = chaotic)\n","        chaos_score = np.tanh(lyapunov_approx * shannon_entropy * (fractal_dim - 1))\n","\n","        # Determine if we're in the \"mellowing\" phase\n","        recent_volatility = np.std(returns[-20:]) if len(returns) > 20 else np.std(returns)\n","        overall_volatility = np.std(returns)\n","        is_mellowing = recent_volatility < overall_volatility * 0.8\n","\n","        return {\n","            'lyapunov_approx': lyapunov_approx,\n","            'shannon_entropy': shannon_entropy,\n","            'fractal_dimension': fractal_dim,\n","            'chaos_score': chaos_score,\n","            'is_mellowing': is_mellowing,\n","            'recent_volatility': recent_volatility,\n","            'volatility_ratio': recent_volatility / (overall_volatility + 1e-10)\n","        }\n","\n","    def generate_intelligent_signals(self, data: pd.DataFrame) -> Dict:\n","        \"\"\"\n","        Generate trading signals using all components.\n","        \"\"\"\n","        # Get all analysis components\n","        phase_evo = self.track_phase_evolution(data)\n","        autocorr = self.leverage_autocorrelation(data)\n","        feigenbaum = self.detect_feigenbaum_transitions(data)\n","        attractors = self.analyze_attractor_dynamics(data)\n","        chaos = self.measure_chaos_level(data)\n","\n","        signals = []\n","        confidence_scores = []\n","\n","        # Determine current market state\n","        if not phase_evo or not chaos:\n","            return {'signals': [0], 'confidence': [0]}\n","\n","        # Current phase from 729-window\n","        current_phase = phase_evo.get('current_phase', self.PHASE_CHAOS)\n","        is_converging = phase_evo.get('is_converging', False)\n","        current_density = phase_evo.get('current_density', 0.5)\n","\n","        # Chaos level\n","        chaos_score = chaos.get('chaos_score', 0.5)\n","        is_mellowing = chaos.get('is_mellowing', False)\n","\n","        # Dominant attractor\n","        dominant_attractor = attractors.get('dominant_attractor', 'none')\n","        attractor_strength = attractors.get('dominant_strength', 0)\n","\n","        # Feigenbaum cascade detection\n","        approaching_chaos = feigenbaum.get('approaching_chaos', False)\n","\n","        # Generate signals based on market state\n","        n_signals = min(len(data), 100)  # Generate reasonable number of signals\n","\n","        for i in range(n_signals):\n","            signal = 0\n","            confidence = 0\n","\n","            # Trading logic based on discoveries\n","            if current_phase == self.PHASE_CONVERGING and is_converging:\n","                # System is converging to attractor - trade toward it\n","                if dominant_attractor == 'inv_phi_squared' and current_density > 0.382:\n","                    signal = -1  # Sell to converge down\n","                    confidence = attractor_strength\n","                elif dominant_attractor == 'phi_conjugate' and current_density < 0.618:\n","                    signal = 1  # Buy to converge up\n","                    confidence = attractor_strength\n","                elif dominant_attractor == 'unity':\n","                    # Mean reversion\n","                    if current_density > 0.5:\n","                        signal = -1\n","                    else:\n","                        signal = 1\n","                    confidence = attractor_strength * 0.8\n","\n","            elif current_phase == self.PHASE_STABLE and is_mellowing:\n","                # System is stable and mellowing - can use autocorrelation\n","                if 'signals' in autocorr and i < len(autocorr['signals']):\n","                    signal = autocorr['signals'][i]\n","                    confidence = autocorr.get('signal_confidence', 0.5)\n","\n","            elif approaching_chaos and not is_mellowing:\n","                # Approaching chaos - reduce position or stay out\n","                signal = 0\n","                confidence = 0.1\n","\n","            # Modulate by chaos score\n","            if chaos_score > 0.7:\n","                # High chaos - reduce confidence\n","                confidence *= 0.5\n","                if abs(signal) > 0:\n","                    signal = signal * 0.5  # Reduce position size\n","\n","            # Check for critical number appearance\n","            if phase_evo.get('attractor_distances', []):\n","                min_distance = min(phase_evo['attractor_distances'])\n","                if abs(min_distance - self.CRITICAL_NUMBER) < 0.001:\n","                    # Critical number detected - strong signal\n","                    confidence = min(confidence * 2, 1.0)\n","\n","            signals.append(signal)\n","            confidence_scores.append(confidence)\n","\n","        # Calculate expected Sharpe based on conditions\n","        expected_sharpe = 0\n","        if is_converging and is_mellowing and chaos_score < 0.3:\n","            expected_sharpe = 0.5  # Good conditions\n","        elif current_phase == self.PHASE_STABLE:\n","            expected_sharpe = 0.3  # Decent conditions\n","        elif approaching_chaos:\n","            expected_sharpe = -0.1  # Poor conditions\n","\n","        return {\n","            'signals': signals,\n","            'confidence': confidence_scores,\n","            'mean_confidence': np.mean(confidence_scores),\n","            'expected_sharpe': expected_sharpe,\n","            'trading_mode': self._get_trading_mode(current_phase, chaos_score, is_mellowing),\n","            'recommendation': self._get_recommendation(phase_evo, chaos, attractors)\n","        }\n","\n","    def _classify_phase(self, density: float, velocity: float, acceleration: float) -> int:\n","        \"\"\"Classify current phase based on dynamics.\"\"\"\n","\n","        # Check if we're near an attractor\n","        min_distance = min(abs(density - v) for v in self.ATTRACTORS.values() if 0 <= v <= 1)\n","\n","        if min_distance < 0.05 and abs(velocity) < 0.001:\n","            return self.PHASE_STABLE\n","        elif abs(acceleration) > 0.0001 and abs(velocity) > 0.005:\n","            return self.PHASE_CHAOS\n","        elif min_distance < 0.1 and abs(velocity) < 0.01:\n","            return self.PHASE_CONVERGING\n","        else:\n","            return self.PHASE_TRANSITION\n","\n","    def _detect_convergence(self, densities: np.ndarray, distances: List[float]) -> bool:\n","        \"\"\"Detect if system is converging to attractor.\"\"\"\n","        if len(distances) < 3:\n","            return False\n","\n","        # Check if distances are decreasing\n","        recent_distances = distances[-5:] if len(distances) >= 5 else distances\n","\n","        # Linear regression on distances\n","        x = np.arange(len(recent_distances))\n","        slope = np.polyfit(x, recent_distances, 1)[0]\n","\n","        return slope < -0.001  # Negative slope = converging\n","\n","    def _calculate_mellowing(self, densities: np.ndarray) -> float:\n","        \"\"\"Calculate how much the system is 'mellowing' (stabilizing).\"\"\"\n","        if len(densities) < 10:\n","            return 0\n","\n","        # Compare early volatility to recent volatility\n","        early_vol = np.std(densities[:len(densities)//2])\n","        recent_vol = np.std(densities[len(densities)//2:])\n","\n","        if early_vol > 0:\n","            mellowing = 1 - (recent_vol / early_vol)\n","            return max(0, min(1, mellowing))\n","        return 0\n","\n","    def _get_trading_mode(self, phase: int, chaos_score: float, is_mellowing: bool) -> str:\n","        \"\"\"Determine appropriate trading mode.\"\"\"\n","        if phase == self.PHASE_STABLE and is_mellowing:\n","            return \"FULL_POSITION\"\n","        elif phase == self.PHASE_CONVERGING and chaos_score < 0.5:\n","            return \"ACCUMULATE\"\n","        elif phase == self.PHASE_CHAOS or chaos_score > 0.7:\n","            return \"RISK_OFF\"\n","        else:\n","            return \"CAUTIOUS\"\n","\n","    def _get_recommendation(self, phase_evo: Dict, chaos: Dict, attractors: Dict) -> str:\n","        \"\"\"Get human-readable recommendation.\"\"\"\n","        if not phase_evo or not chaos:\n","            return \"Insufficient data for recommendation\"\n","\n","        phase = phase_evo.get('current_phase', self.PHASE_CHAOS)\n","        chaos_score = chaos.get('chaos_score', 0.5)\n","        dominant = attractors.get('dominant_attractor', 'none')\n","\n","        if phase == self.PHASE_STABLE and chaos_score < 0.3:\n","            return f\"Strong signal: System stable near {dominant} attractor\"\n","        elif phase == self.PHASE_CONVERGING:\n","            return f\"Moderate signal: Converging toward {dominant}\"\n","        elif phase == self.PHASE_CHAOS:\n","            return \"Weak signal: System in chaos, avoid trading\"\n","        else:\n","            return \"Neutral: System in transition, wait for clarity\"\n","\n","\n","def run_advanced_test(data: pd.DataFrame) -> Dict:\n","    \"\"\"\n","    Run the advanced pattern predictor on data.\n","    \"\"\"\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"ADVANCED PATTERN EVOLUTION TEST\")\n","    print(\"=\"*60)\n","\n","    predictor = AdvancedPatternPredictor()\n","    results = predictor.analyze_complete(data)\n","\n","    # Print summary\n","    print(\"\\nðŸ“Š Phase Evolution:\")\n","    if 'phase_evolution' in results and results['phase_evolution']:\n","        phase_evo = results['phase_evolution']\n","        print(f\"  Current Phase: {phase_evo.get('current_phase', 'Unknown')}\")\n","        print(f\"  Current Density: {phase_evo.get('current_density', 0):.6f}\")\n","        print(f\"  Converging: {phase_evo.get('is_converging', False)}\")\n","        print(f\"  Mellowing Score: {phase_evo.get('mellowing_score', 0):.3f}\")\n","\n","    print(\"\\nðŸ”„ Autocorrelation:\")\n","    if 'autocorr_signals' in results and results['autocorr_signals']:\n","        autocorr = results['autocorr_signals']\n","        print(f\"  Lag-42 Strength: {autocorr.get('lag_42_strength', 0):.6f}\")\n","        print(f\"  Lag-45 Strength: {autocorr.get('lag_45_strength', 0):.6f}\")\n","        print(f\"  Signal Confidence: {autocorr.get('signal_confidence', 0):.3f}\")\n","\n","    print(\"\\nðŸŒ€ Feigenbaum Detection:\")\n","    if 'feigenbaum_detection' in results and results['feigenbaum_detection']:\n","        feig = results['feigenbaum_detection']\n","        print(f\"  Approaching Chaos: {feig.get('approaching_chaos', False)}\")\n","        print(f\"  Chaos Parameter: {feig.get('chaos_parameter', 0):.6f}\")\n","        print(f\"  Critical Echo: {feig.get('has_critical_echo', False)}\")\n","\n","    print(\"\\nðŸŽ¯ Attractor Dynamics:\")\n","    if 'attractor_dynamics' in results and results['attractor_dynamics']:\n","        attract = results['attractor_dynamics']\n","        print(f\"  Dominant: {attract.get('dominant_attractor', 'none')}\")\n","        print(f\"  Strength: {attract.get('dominant_strength', 0):.3f}\")\n","\n","    print(\"\\nðŸ“ˆ Trading Signals:\")\n","    if 'trading_signals' in results and results['trading_signals']:\n","        signals = results['trading_signals']\n","        print(f\"  Mode: {signals.get('trading_mode', 'Unknown')}\")\n","        print(f\"  Expected Sharpe: {signals.get('expected_sharpe', 0):.3f}\")\n","        print(f\"  Mean Confidence: {signals.get('mean_confidence', 0):.3f}\")\n","        print(f\"  Recommendation: {signals.get('recommendation', 'None')}\")\n","\n","    print(\"\\nðŸ’« Chaos Metrics:\")\n","    if 'chaos_metrics' in results and results['chaos_metrics']:\n","        chaos = results['chaos_metrics']\n","        print(f\"  Chaos Score: {chaos.get('chaos_score', 0):.3f}\")\n","        print(f\"  Is Mellowing: {chaos.get('is_mellowing', False)}\")\n","        print(f\"  Fractal Dimension: {chaos.get('fractal_dimension', 0):.3f}\")\n","\n","    return results\n","\n","\n","# Test function to validate with your data\n","def validate_predictor(symbol: str = 'SPY', start: str = '2020-01-01', end: str = '2024-10-31'):\n","    \"\"\"\n","    Validate the predictor with real or synthetic data.\n","    \"\"\"\n","    try:\n","        # Try to get real data\n","        import yfinance as yf\n","        data = yf.download(symbol, start=start, end=end)\n","        data['returns'] = data['Close'].pct_change()\n","        print(f\"Using real data for {symbol}\")\n","    except:\n","        # Generate synthetic data for testing\n","        print(\"Using synthetic data for testing\")\n","        dates = pd.date_range(start=start, end=end, freq='D')\n","        prices = 100 * (1 + np.random.randn(len(dates)).cumsum() * 0.01)\n","        data = pd.DataFrame({\n","            'Close': prices,\n","            'Open': prices * (1 + np.random.randn(len(dates)) * 0.01),\n","            'High': prices * (1 + np.abs(np.random.randn(len(dates)) * 0.02)),\n","            'Low': prices * (1 - np.abs(np.random.randn(len(dates)) * 0.02)),\n","            'Volume': np.random.pareto(2, len(dates)) * 1000000,\n","            'returns': np.diff(prices, prepend=prices[0]) / prices\n","        }, index=dates)\n","\n","    # Run the advanced test\n","    results = run_advanced_test(data)\n","\n","    # Calculate actual Sharpe if we have signals\n","    if 'trading_signals' in results and results['trading_signals'].get('signals'):\n","        signals = np.array(results['trading_signals']['signals'])\n","        returns = data['returns'].values[-len(signals):]\n","\n","        strategy_returns = signals * returns\n","        actual_sharpe = np.mean(strategy_returns) / (np.std(strategy_returns) + 1e-10)\n","\n","        print(\"\\n\" + \"=\"*60)\n","        print(f\"ACTUAL SHARPE RATIO: {actual_sharpe:.4f}\")\n","        print(f\"Expected Sharpe: {results['trading_signals'].get('expected_sharpe', 0):.4f}\")\n","        print(\"=\"*60)\n","\n","    return results\n","\n","# Example usage:\n","# results = validate_predictor('SPY', '2020-01-01', '2024-10-31')"]}]}