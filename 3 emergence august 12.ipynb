{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPh65LR+cy45i3NaRllmSnI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JDYCb1Mn3fPz","executionInfo":{"status":"ok","timestamp":1755012053164,"user_tz":240,"elapsed":28187,"user":{"displayName":"Kate Huneke","userId":"12242479504218415499"}},"outputId":"668bc975-afd6-4742-a27e-187c851de3fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== BINARY → DECIMAL EMERGENCE LAB (π-aware, triadic) ===\n","Digits (F prefix) N = 5000\n","DF + DR − 1/9 ≈ 0.000E+00   <-- complement identity (→0 with larger N)\n","\n","--- Triadic scan for F (base-10) ---\n","α (B) = 0.0072973525693\n","Best k (base-10) = 6  m = 729  |Δ| = 1.040E-08\n","Sub-step within one click = 0.001039\n","α* (at best m) = 0.007297362972974\n","\n","--- Prefix scalogram (residual vs N) ---\n","N= 100: residual=1.040E-08\n","N= 200: residual=1.040E-08\n","N= 300: residual=1.040E-08\n","N= 400: residual=1.040E-08\n","N= 600: residual=1.040E-08\n","N= 800: residual=1.040E-08\n","N=1000: residual=1.040E-08\n","N=1500: residual=1.040E-08\n","N=2000: residual=1.040E-08\n","\n","--- Monte Carlo: density-matched ---\n","Trials n=8000, p≈0.0024, median error≈8.035E-04\n","--- Monte Carlo: run-length-matched ---\n","Trials n=3000, p≈0.0313, median error≈6.707E-04\n","\n","Saved CSVs & figures to: /content/out\n"]}],"source":["# ================================================================\n","#  Binary → Decimal Emergence Lab (BDE-Lab v4, π-aware, triadic)\n","#  Self-contained, bias-controlled suite for Colab\n","#  --------------------------------------------------------------\n","#  What it does (no intervention needed):\n","#   • Builds Fibonacci-word (F), Rabbit (R=¬F), reversals, Thue–Morse (TM)\n","#   • Verifies complement identity DF + DR = 1/9 (decimal-digit map)\n","#   • Triadic scan: α* = (3^k / 10^3) · D_B(F) with B∈{10}  (main) + base-B head-to-head\n","#   • Picks best k by |α*-α|; reports sub-step within one 10^-3 “click”\n","#   • Prefix scalogram: stability of residual vs prefix length\n","#   • Monte Carlo controls (pre-registered): density‑matched & runlength‑matched\n","#   • Sequence specificity (F, R, F_rev, R_rev, TM) in base‑10\n","#   • Base‑B head-to-head: B ∈ {7,8,9,10,12} with triadic multipliers\n","#   • π control: triadic n-gon bounds; two “binary chord” toys (clearly marked as toys)\n","#  Saves results to /content/out as PNGs and CSV/JSON.\n","# ================================================================\n","\n","import os, math, json, time, itertools, statistics\n","from collections import Counter, deque\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# -------------------------\n","# Reproducibility & knobs\n","# -------------------------\n","SEED = 137\n","rng = np.random.default_rng(SEED)\n","\n","# Core precision knobs (you can leave these alone)\n","N_DIGITS     = 5000        # how many Fibonacci bits mapped to digits (main tests use 1000–5000 just fine)\n","K_RANGE      = range(0, 13) # explore multipliers m = 3^k\n","MC_DENSITY_N = 8000        # Monte-Carlo trials (density matched)\n","MC_RUNLEN_N  = 3000        # Monte-Carlo trials (run-length matched)\n","\n","BASES = [7, 8, 9, 10, 12]  # base-B head-to-head\n","SEQ_TAGS = [\"F\", \"R\", \"F_rev\", \"R_rev\", \"TM\"]  # sequence specificity catalogue\n","\n","# Two close reference α values (stable to >10 decimals; update when CODATA updates)\n","ALPHA_A = 0.0072973525643\n","ALPHA_B = 0.0072973525693\n","ALPHAS = [(\"A\", ALPHA_A), (\"B\", ALPHA_B)]\n","\n","OUTDIR = \"/content/out\"\n","os.makedirs(OUTDIR, exist_ok=True)\n","\n","# -------------------------\n","# Utilities\n","# -------------------------\n","def fib_word_bits(N: int) -> np.ndarray:\n","    \"\"\"Fibonacci word starting from '0' with morphism 0→01, 1→0; returns first N bits (0/1).\"\"\"\n","    s = \"0\"\n","    def morph(x):\n","        # 0->01, 1->0\n","        return \"\".join((\"01\" if ch==\"0\" else \"0\") for ch in x)\n","    while len(s) < N:\n","        s = morph(s)\n","    return np.fromiter((1 if c=='1' else 0 for c in s[:N]), dtype=np.uint8)\n","\n","def thue_morse_bits(N: int) -> np.ndarray:\n","    \"\"\"Thue-Morse: t(n) = parity of ones in binary of n (starting n=0).\"\"\"\n","    # vectorized popcount parity\n","    idx = np.arange(N, dtype=np.uint64)\n","    # builtin popcount via bit tricks (numpy 1.23+ has bit_count on int, but keep portable)\n","    def bitcount(x):\n","        c = 0\n","        while x:\n","            x &= x-1\n","            c += 1\n","        return c\n","    # faster: use python int bit_count when available\n","    par = np.fromiter(((int(i).bit_count() & 1) for i in idx), dtype=np.uint8)\n","    return par\n","\n","def digits_value(bits: np.ndarray, base: int) -> float:\n","    \"\"\"Map 0/1 bits to base-B digits → real in [0,1): 0.b1 b2 ... (base B). Stable reversed division.\"\"\"\n","    val = 0.0\n","    b = float(base)\n","    # reverse Horner\n","    for d in bits[::-1]:\n","        val = (val + float(d)) / b\n","    return val\n","\n","def run_lengths(bits: np.ndarray):\n","    \"\"\"Return list of contiguous run lengths and starting bit.\"\"\"\n","    if len(bits)==0: return [], 0\n","    runs = []\n","    cur = int(bits[0]); count = 1\n","    for x in bits[1:]:\n","        if int(x)==cur:\n","            count += 1\n","        else:\n","            runs.append((cur, count))\n","            cur = int(x); count = 1\n","    runs.append((cur, count))\n","    return runs, int(bits[0])\n","\n","def sample_runlength_shuffled(bits: np.ndarray, rng: np.random.Generator):\n","    \"\"\"Shuffle run lengths separately for 0-runs and 1-runs, then interleave starting with original start bit.\"\"\"\n","    runs, start = run_lengths(bits)\n","    lens0 = [L for b,L in runs if b==0]\n","    lens1 = [L for b,L in runs if b==1]\n","    rng.shuffle(lens0); rng.shuffle(lens1)\n","    i0=i1=0\n","    # reconstruct\n","    out = np.empty_like(bits)\n","    pos = 0\n","    bit = start\n","    total_runs = len(runs)\n","    for _ in range(total_runs):\n","        if bit==0:\n","            L = lens0[i0]; i0+=1\n","        else:\n","            L = lens1[i1]; i1+=1\n","        out[pos:pos+L] = bit\n","        pos += L\n","        bit = 1-bit\n","    return out\n","\n","def best_alpha_error_for_sequence(bits, base, k_range, denom_power=3, alpha=ALPHA_B):\n","    \"\"\"Return best (k, m=3^k, alpha_star, abs_error) for given sequence and base.\"\"\"\n","    D = digits_value(bits, base)\n","    denom = base**denom_power\n","    rec = []\n","    for k in k_range:\n","        m = 3**k\n","        a_star = (m/denom)*D\n","        rec.append((k, m, a_star, abs(a_star-alpha)))\n","    return min(rec, key=lambda t: t[3]), D\n","\n","def summarize_alpha_scan(bits, base, k_range, denom_power=3):\n","    \"\"\"Scan vs both alphas; also compute sub-step ratio.\"\"\"\n","    results = []\n","    D = digits_value(bits, base)\n","    denom = base**denom_power\n","    click = D/denom  # one-click spacing for changing m by 1\n","    for label, alpha in ALPHAS:\n","        best = None\n","        for k in k_range:\n","            m = 3**k\n","            a_star = (m/denom)*D\n","            err = abs(a_star-alpha)\n","            if (best is None) or (err<best[3]):\n","                best = (k, m, a_star, err)\n","        substep = best[3]/click if click>0 else float('nan')\n","        results.append(dict(alpha_label=label, alpha=alpha,\n","                            k_best=best[0], m_best=best[1],\n","                            alpha_star=best[2], abs_error=best[3],\n","                            substep_within_click=substep))\n","    return results, D, click\n","\n","def plot_save(fname):\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(OUTDIR, fname), dpi=160)\n","    plt.close()\n","\n","# -------------------------\n","# Build sequences (prefix N_DIGITS)\n","# -------------------------\n","t0 = time.time()\n","F_bits = fib_word_bits(N_DIGITS)\n","R_bits = 1 - F_bits\n","F_rev = F_bits[::-1]\n","R_rev = R_bits[::-1]\n","TM_bits = thue_morse_bits(N_DIGITS)\n","\n","SEQ_MAP = {\n","    \"F\": F_bits, \"R\": R_bits,\n","    \"F_rev\": F_rev, \"R_rev\": R_rev,\n","    \"TM\": TM_bits\n","}\n","\n","# -------------------------\n","# Quick identity check: DF + DR = 1/9 (no carries in decimal-digit map)\n","# -------------------------\n","DF = digits_value(F_bits, 10)\n","DR = digits_value(R_bits, 10)\n","comp_err = DF + DR - (1/9)\n","\n","# -------------------------\n","# Main triadic scan (base-10, Fibonacci)\n","# -------------------------\n","scan_records = []\n","scan, D_main, click_main = summarize_alpha_scan(F_bits, base=10, k_range=K_RANGE, denom_power=3)\n","for rec in scan:\n","    rec2 = dict(rec)\n","    rec2[\"base\"] = 10\n","    rec2[\"sequence\"] = \"F\"\n","    scan_records.append(rec2)\n","\n","df_scan = pd.DataFrame(scan_records)\n","df_scan.to_csv(os.path.join(OUTDIR, \"scan_triadic_F_base10.csv\"), index=False)\n","\n","# Plot error vs k for ALPHA_B (the second is nearly identical scale)\n","errs = []\n","for k in K_RANGE:\n","    m = 3**k\n","    a_star = (m/1000)*D_main\n","    errs.append(abs(a_star - ALPHA_B))\n","plt.figure(figsize=(7,4.5))\n","plt.plot(list(K_RANGE), errs, marker=\"o\")\n","plt.xlabel(\"k (m = 3^k)\")\n","plt.ylabel(\"absolute error |α* − α|\")\n","plt.title(\"Error | (3^k / 10^3) · D(F) − α |  (base-10)\")\n","# Highlight best k\n","k_best = int(df_scan[df_scan.alpha_label==\"B\"].iloc[0][\"k_best\"])\n","plt.scatter([k_best],[errs[k_best]], s=80)\n","plot_save(\"plot_scan_3k_base10.png\")\n","\n","# -------------------------\n","# Prefix scalogram (stability at fixed m=3^k where k_best from ALPHA_B)\n","# -------------------------\n","prefix_list = [100,200,300,400,600,800,1000,1500,2000]\n","resid = []\n","for N in prefix_list:\n","    Dp = digits_value(F_bits[:N], 10)\n","    a_star = ( (3**k_best) / 1000 ) * Dp\n","    resid.append(a_star - ALPHA_B)\n","\n","df_scalo = pd.DataFrame({\"prefix_N\": prefix_list, \"alpha_star_minus_alpha\": resid})\n","df_scalo.to_csv(os.path.join(OUTDIR, \"prefix_scalogram.csv\"), index=False)\n","\n","plt.figure(figsize=(7,4.5))\n","plt.plot(prefix_list, resid, marker=\"o\")\n","plt.axhline(0, ls=\"--\", lw=1)\n","plt.title(f\"Prefix scalogram at m=3^{k_best} (base-10)\")\n","plt.xlabel(\"prefix length N\")\n","plt.ylabel(\"α* − α\")\n","plot_save(\"plot_prefix_scalogram.png\")\n","\n","# -------------------------\n","# Sequence specificity (base-10; best over k)\n","# -------------------------\n","spec_rows = []\n","for tag in SEQ_TAGS:\n","    best_B, Dtmp = best_alpha_error_for_sequence(SEQ_MAP[tag], base=10, k_range=K_RANGE, denom_power=3, alpha=ALPHA_B)\n","    spec_rows.append(dict(sequence=tag, k_best=best_B[0], m_best=best_B[1],\n","                          alpha_star=best_B[2], abs_error=best_B[3]))\n","df_spec = pd.DataFrame(spec_rows)\n","df_spec.to_csv(os.path.join(OUTDIR, \"sequence_specificity.csv\"), index=False)\n","\n","plt.figure(figsize=(7.5,4.5))\n","plt.bar(df_spec[\"sequence\"], df_spec[\"abs_error\"])\n","for i,row in df_spec.iterrows():\n","    plt.text(i, row[\"abs_error\"]+1e-5, f'k={int(row[\"k_best\"])}', ha='center', va='bottom', fontsize=9)\n","plt.ylabel(\"best |α* − α|\")\n","plt.title(\"Sequence specificity (base-10)\")\n","plot_save(\"plot_invariance.png\")\n","\n","# -------------------------\n","# Base-B head-to-head (use same triadic rule α*=(3^k / B^3)·D_B(F))\n","# -------------------------\n","bb_rows = []\n","for B in BASES:\n","    D_B = digits_value(F_bits, B)\n","    denom = B**3\n","    best = None\n","    for k in K_RANGE:\n","        m = 3**k\n","        a_star = (m/denom)*D_B\n","        err = abs(a_star-ALPHA_B)\n","        if (best is None) or (err<best[3]):\n","            best = (k,m,a_star,err)\n","    bb_rows.append(dict(base=B, k_best=best[0], m_best=best[1], alpha_star=best[2], abs_error=best[3]))\n","df_base = pd.DataFrame(bb_rows)\n","df_base.to_csv(os.path.join(OUTDIR, \"baseB_headtohead.csv\"), index=False)\n","\n","plt.figure(figsize=(7,4.5))\n","plt.bar([str(B) for B in df_base[\"base\"]], df_base[\"abs_error\"])\n","plt.xlabel(\"base B (digits interpreted in base B)\")\n","plt.ylabel(\"best |α* − α|\")\n","plt.title(\"Base sensitivity (F)\")\n","plot_save(\"plot_baseB_headtohead.png\")\n","\n","# -------------------------\n","# Monte Carlo controls\n","#   Hypothesis class (pre-registered):\n","#    • sequences length N_DIGITS\n","#    • base = 10\n","#    • multipliers m = 3^k, k ∈ K_RANGE\n","#   We compute p = P(err_random ≤ err_F).\n","# -------------------------\n","# Target error (F, base-10, best over k)\n","err_F_target = float(df_spec[df_spec.sequence==\"F\"][\"abs_error\"].iloc[0])\n","\n","# Density-matched trials\n","p1 = float(F_bits.mean())\n","den_errors = np.empty(MC_DENSITY_N)\n","for i in range(MC_DENSITY_N):\n","    S = rng.binomial(1, p1, size=N_DIGITS).astype(np.uint8)\n","    best,_ = best_alpha_error_for_sequence(S, base=10, k_range=K_RANGE, denom_power=3, alpha=ALPHA_B)\n","    den_errors[i] = best[3]\n","df_den = pd.DataFrame({\"abs_error\": den_errors})\n","df_den.to_csv(os.path.join(OUTDIR, \"mc_density_errors.csv\"), index=False)\n","pval_density = float(np.mean(den_errors <= err_F_target))\n","med_density  = float(np.median(den_errors))\n","\n","plt.figure(figsize=(7.5,4.5))\n","plt.hist(den_errors, bins=60)\n","plt.axvline(err_F_target, ls=\"--\")\n","plt.title(f\"Monte Carlo (density-matched): errors vs DF (k best per trial)\\nN={MC_DENSITY_N}, p≈{pval_density:.4f}\")\n","plt.xlabel(\"abs error\")\n","plt.ylabel(\"count\")\n","plot_save(\"plot_mc_density.png\")\n","\n","# Run-length matched trials\n","run_errors = np.empty(MC_RUNLEN_N)\n","for i in range(MC_RUNLEN_N):\n","    S = sample_runlength_shuffled(F_bits, rng)\n","    best,_ = best_alpha_error_for_sequence(S, base=10, k_range=K_RANGE, denom_power=3, alpha=ALPHA_B)\n","    run_errors[i] = best[3]\n","df_run = pd.DataFrame({\"abs_error\": run_errors})\n","df_run.to_csv(os.path.join(OUTDIR, \"mc_runlength_errors.csv\"), index=False)\n","pval_run = float(np.mean(run_errors <= err_F_target))\n","med_run  = float(np.median(run_errors))\n","\n","plt.figure(figsize=(7.5,4.5))\n","plt.hist(run_errors, bins=60)\n","plt.axvline(err_F_target, ls=\"--\")\n","plt.title(f\"Monte Carlo (run-length-matched): errors vs DF (k best per trial)\\nN={MC_RUNLEN_N}, p≈{pval_run:.4f}\")\n","plt.xlabel(\"abs error\")\n","plt.ylabel(\"count\")\n","plot_save(\"plot_mc_runlength.png\")\n","\n","# -------------------------\n","# π MODULE (controls + toys) — clearly separated\n","# -------------------------\n","# 1) Triadic polygon bounds to π (pure control, no sequences)\n","def triadic_bounds_to_pi(k_vals):\n","    rows=[]\n","    for k in k_vals:\n","        n = 3**k\n","        pin  = n*math.sin(math.pi/n)        # (= P_in / 2 for unit circle)\n","        pout = n*math.tan(math.pi/n)        # (= P_out / 2)\n","        rows.append(dict(k=k, n=n, pin=pin, pout=pout, err_in=pin-math.pi, err_out=pout-math.pi))\n","    return pd.DataFrame(rows)\n","\n","df_bounds = triadic_bounds_to_pi(range(1,9))\n","df_bounds.to_csv(os.path.join(OUTDIR, \"triadic_bounds_control.csv\"), index=False)\n","plt.figure(figsize=(7.5,4.5))\n","plt.plot(df_bounds[\"k\"], df_bounds[\"err_out\"], marker=\"o\", label=\"p_out - π (circumscribed)\")\n","plt.plot(df_bounds[\"k\"], df_bounds[\"err_in\"],  marker=\"o\", label=\"p_in - π (inscribed)\")\n","plt.axhline(0, ls=\"--\", lw=1)\n","plt.xlabel(\"k  (n = 3^k)\")\n","plt.ylabel(\"error relative to π\")\n","plt.title(\"Triadic regular polygons: bounds to π (control)\")\n","plt.legend()\n","plot_save(\"triadic_bounds_control.png\")\n","\n","# 2) Binary chord (toy): “walk” angles by golden angle and sum chord lengths selected by bits\n","def binary_chord_pi_estimate(bits, step=\"golden\"):\n","    M = len(bits)\n","    if step==\"golden\":\n","        # golden angle step on the circle\n","        g = (math.sqrt(5)-1)/2\n","        dtheta = 2*math.pi*(1-g)            # ~137.5°\n","    else:\n","        dtheta = 2*math.pi/ (M//2 or 1)     # safe fallback\n","    theta = 0.0\n","    perim = 0.0\n","    for b in bits:\n","        theta_next = theta + dtheta\n","        if b==1:\n","            # chord length between points at theta and theta_next on unit circle\n","            perim += 2*math.sin(abs(theta_next - theta)/2.0)\n","        theta = theta_next\n","    # Normalize so that if every step produced a chord we would approach 2π\n","    # Using fraction of ones as an occupancy factor:\n","    occ = float(bits.mean()) if float(bits.mean())>0 else 1.0\n","    estimate = (perim / occ) / 2.0\n","    return estimate\n","\n","# Run toy estimates for F/TM and a random baseline\n","est_F  = binary_chord_pi_estimate(F_bits[:5000])\n","est_TM = binary_chord_pi_estimate(TM_bits[:5000])\n","rand_ests = [binary_chord_pi_estimate(rng.integers(0,2, size=5000, dtype=np.uint8)) for _ in range(200)]\n","df_ch = pd.DataFrame(dict(est=[est_F, est_TM], seq=[\"Fibonacci\",\"Thue–Morse\"]))\n","df_rand = pd.DataFrame({\"est\": rand_ests})\n","\n","plt.figure(figsize=(7.5,4.5))\n","plt.hist(df_rand[\"est\"], bins=40, alpha=0.85)\n","plt.axvline(math.pi, ls=\"--\", lw=2, label=\"π (true)\")\n","plt.axvline(est_F,  lw=2, label=f\"Fibonacci est ({est_F:.6f})\")\n","plt.axvline(est_TM, lw=2, ls=\":\", label=f\"Thue–Morse est ({est_TM:.6f})\")\n","plt.title(\"Binary-chord circle (toy): Fibonacci vs random streams\")\n","plt.xlabel(\"π estimate (perimeter / 2)\")\n","plt.ylabel(\"count\")\n","plt.legend()\n","plot_save(\"binary_chord_hist.png\")\n","\n","# 3) Carry-cut residual (toy): push tiny “carry” proportional to triadic scale; compare streams\n","def carry_cut_residual(bits, k_vals):\n","    res=[]\n","    base_click = 1.0 # arbitrary scale\n","    for k in k_vals:\n","        # shrink carry as 3^{-k} (toy)\n","        carry = (3.0**(-k)) * (bits[: 3**k].mean())\n","        res.append(dict(k=k, residual=carry - 0.0))\n","    return pd.DataFrame(res)\n","\n","df_cc_F  = carry_cut_residual(F_bits, range(1,9))\n","df_cc_TM = carry_cut_residual(TM_bits, range(1,9))\n","plt.figure(figsize=(7.5,4.5))\n","plt.plot(df_cc_F[\"k\"],  df_cc_F[\"residual\"],  marker=\"o\", label=\"Fibonacci stream\")\n","plt.plot(df_cc_TM[\"k\"], df_cc_TM[\"residual\"], marker=\"o\", label=\"Thue–Morse stream\")\n","plt.axhline(0, ls=\"--\", lw=1)\n","plt.title('\"Carry-cut\" residual vs triadic level (toy)')\n","plt.xlabel(\"k  (n = 3^k)\")\n","plt.ylabel(\"adjusted perimeter − π  (toy units)\")\n","plt.legend()\n","plot_save(\"carry_cut_residual.png\")\n","\n","# -------------------------\n","# Final summary + JSON\n","# -------------------------\n","summary = {\n","    \"digits_used_N\": N_DIGITS,\n","    \"complement_identity_DF_plus_DR_minus_1_over_9\": comp_err,\n","    \"alpha_inputs\": {lbl: val for lbl,val in ALPHAS},\n","    \"scan_F_base10\": df_scan.to_dict(orient=\"records\"),\n","    \"k_best_B\": k_best,\n","    \"click_size_D_over_1000\": click_main,\n","    \"prefix_scalogram_points\": df_scalo.to_dict(orient=\"records\"),\n","    \"sequence_specificity\": df_spec.to_dict(orient=\"records\"),\n","    \"baseB_headtohead\": df_base.to_dict(orient=\"records\"),\n","    \"mc_density\": {\"N\": MC_DENSITY_N, \"p_value\": pval_density, \"median_error\": med_density},\n","    \"mc_runlength\": {\"N\": MC_RUNLEN_N, \"p_value\": pval_run, \"median_error\": med_run},\n","    \"pi_control\": {\n","        \"triadic_bounds_last_row\": df_bounds.iloc[-1].to_dict(),\n","        \"binary_chord_toy\": {\"F\": est_F, \"TM\": est_TM, \"random_mean\": float(df_rand[\"est\"].mean()),\n","                             \"random_sd\": float(df_rand[\"est\"].std(ddof=1))}\n","    },\n","    \"runtime_sec\": time.time() - t0,\n","    \"outdir\": OUTDIR,\n","    \"notes\": [\n","        \"Main α rule: α* = (3^k / 10^3) · D_10(sequence). k chosen by minimizing |α*−α| over K_RANGE.\",\n","        \"Monte-Carlo p-values computed inside the pre-registered hypothesis class (seq length N, base=10, multipliers 3^k).\",\n","        \"Base-B head-to-head uses α* = (3^k / B^3) · D_B(F) to keep dimensions consistent.\",\n","        \"π module is for control/toy intuition only; it does not feed back into α claims.\"\n","    ]\n","}\n","with open(os.path.join(OUTDIR, \"summary.json\"), \"w\") as f:\n","    json.dump(summary, f, indent=2)\n","\n","# Console report\n","print(\"=== BINARY → DECIMAL EMERGENCE LAB (π-aware, triadic) ===\")\n","print(f\"Digits (F prefix) N = {N_DIGITS}\")\n","print(f\"DF + DR − 1/9 ≈ {comp_err:.3E}   <-- complement identity (→0 with larger N)\")\n","for row in df_scan.itertuples():\n","    if row.alpha_label==\"B\":\n","        print(\"\\n--- Triadic scan for F (base-10) ---\")\n","        print(f\"α (B) = {ALPHA_B:.13f}\")\n","        print(f\"Best k (base-10) = {int(row.k_best)}  m = {int(row.m_best)}  |Δ| = {row.abs_error:.3E}\")\n","        print(f\"Sub-step within one click = {row.substep_within_click:.6f}\")\n","        print(f\"α* (at best m) = {row.alpha_star:.15f}\")\n","        break\n","print(\"\\n--- Prefix scalogram (residual vs N) ---\")\n","for N, r in zip(df_scalo[\"prefix_N\"], df_scalo[\"alpha_star_minus_alpha\"]):\n","    print(f\"N={N:4d}: residual={r:.3E}\")\n","print(\"\\n--- Monte Carlo: density-matched ---\")\n","print(f\"Trials n={MC_DENSITY_N}, p≈{pval_density:.4f}, median error≈{med_density:.3E}\")\n","print(\"--- Monte Carlo: run-length-matched ---\")\n","print(f\"Trials n={MC_RUNLEN_N}, p≈{pval_run:.4f}, median error≈{med_run:.3E}\")\n","print(f\"\\nSaved CSVs & figures to: {OUTDIR}\")\n"]}]}