{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNqHJyioLF1XQhkFS/eNENy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"4bnfQF-M9zUg","executionInfo":{"status":"ok","timestamp":1754930250717,"user_tz":240,"elapsed":11576,"user":{"displayName":"Kate Huneke","userId":"12242479504218415499"}},"outputId":"9bc3c7f7-f5c3-4794-b29f-22b9fc7f55e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["[WARN] Failed to load jla: JLA mub download failed.\n","\n","=== Binary constants (first few) ===\n","               D7F = 0.0204688800999167468\n","               D7R = 0.146197786566749921\n","           D7F_rev = 0.00297512793032045581\n","           D7R_rev = 0.163691538736346204\n","           neg_D7F = -0.0204688800999167468\n","           neg_D7R = -0.146197786566749921\n","       neg_D7F_rev = -0.00297512793032045581\n","       neg_D7R_rev = -0.163691538736346204\n","               D8F = 0.0156559953484532444\n","               D8R = 0.127201147508689605\n","           D8F_rev = 0.00198370311591494763\n","           D8R_rev = 0.140873439741227902\n","... total constants: 46\n","\n","=== DATASET: Union2.1 (N=580) ===\n","Fitting ΛCDM ...\n","Fitting Const‑w ...\n","Fitting w0–wₐ ...\n","Fitting Binary w(a)=−log₂a ...\n","Fitting ScaleLog c≈0.0204689 [D7F] ...\n","Fitting ScaleLog c≈0.146198 [D7R] ...\n","Fitting ScaleLog c≈0.00297513 [D7F_rev] ...\n","Fitting ScaleLog c≈0.163692 [D7R_rev] ...\n","Fitting ScaleLog c≈-0.0204689 [neg_D7F] ...\n","Fitting ScaleLog c≈-0.146198 [neg_D7R] ...\n","Fitting ScaleLog c≈-0.00297513 [neg_D7F_rev] ...\n","Fitting ScaleLog c≈-0.163692 [neg_D7R_rev] ...\n","Fitting ScaleLog c≈0.015656 [D8F] ...\n","Fitting ScaleLog c≈0.127201 [D8R] ...\n","Fitting ScaleLog c≈0.0019837 [D8F_rev] ...\n","Fitting ScaleLog c≈0.140873 [D8R_rev] ...\n","Fitting ScaleLog c≈-0.015656 [neg_D8F] ...\n","Fitting ScaleLog c≈-0.127201 [neg_D8R] ...\n","Fitting ScaleLog c≈-0.0019837 [neg_D8F_rev] ...\n","Fitting ScaleLog c≈-0.140873 [neg_D8R_rev] ...\n","Fitting ScaleLog c≈0.0123628 [D9F] ...\n","Fitting ScaleLog c≈0.112637 [D9R] ...\n","Fitting ScaleLog c≈0.0013887 [D9F_rev] ...\n","Fitting ScaleLog c≈0.123611 [D9R_rev] ...\n","Fitting ScaleLog c≈-0.0123628 [neg_D9F] ...\n","Fitting ScaleLog c≈-0.112637 [neg_D9R] ...\n","Fitting ScaleLog c≈-0.0013887 [neg_D9F_rev] ...\n","Fitting ScaleLog c≈-0.123611 [neg_D9R_rev] ...\n","Fitting ScaleLog c≈0.0100101 [D10F] ...\n","Fitting ScaleLog c≈0.101101 [D10R] ...\n","Fitting ScaleLog c≈0.00101001 [D10F_rev] ...\n","Fitting ScaleLog c≈0.110101 [D10R_rev] ...\n","Fitting ScaleLog c≈-0.0100101 [neg_D10F] ...\n","Fitting ScaleLog c≈-0.101101 [neg_D10R] ...\n","Fitting ScaleLog c≈-0.00101001 [neg_D10F_rev] ...\n","Fitting ScaleLog c≈-0.110101 [neg_D10R_rev] ...\n","Fitting ScaleLog c≈0.00694849 [D12F] ...\n","Fitting ScaleLog c≈0.0839606 [D12R] ...\n","Fitting ScaleLog c≈0.000582725 [D12F_rev] ...\n","Fitting ScaleLog c≈0.0903264 [D12R_rev] ...\n","Fitting ScaleLog c≈-0.00694849 [neg_D12F] ...\n","Fitting ScaleLog c≈-0.0839606 [neg_D12R] ...\n","Fitting ScaleLog c≈-0.000582725 [neg_D12F_rev] ...\n","Fitting ScaleLog c≈-0.0903264 [neg_D12R_rev] ...\n","Fitting ScaleLog c≈0.98999 [OneMinus_D10F] ...\n","Fitting ScaleLog c≈-0.98999 [neg_OneMinus_D10F] ...\n","Fitting ScaleLog c≈0.290197 [BinF] ...\n","Fitting ScaleLog c≈0.709803 [BinR] ...\n","Fitting ScaleLog c≈-0.290197 [neg_BinF] ...\n","Fitting ScaleLog c≈-0.709803 [neg_BinR] ...\n","Fitting OffsetLog b≈0.0204689 [D7F] ...\n","Fitting OffsetLog b≈0.146198 [D7R] ...\n","Fitting OffsetLog b≈0.00297513 [D7F_rev] ...\n","Fitting OffsetLog b≈0.163692 [D7R_rev] ...\n","Fitting OffsetLog b≈-0.0204689 [neg_D7F] ...\n","Fitting OffsetLog b≈-0.146198 [neg_D7R] ...\n","Fitting OffsetLog b≈-0.00297513 [neg_D7F_rev] ...\n","Fitting OffsetLog b≈-0.163692 [neg_D7R_rev] ...\n","Fitting OffsetLog b≈0.015656 [D8F] ...\n","Fitting OffsetLog b≈0.127201 [D8R] ...\n","Fitting OffsetLog b≈0.0019837 [D8F_rev] ...\n","Fitting OffsetLog b≈0.140873 [D8R_rev] ...\n","Fitting OffsetLog b≈-0.015656 [neg_D8F] ...\n","Fitting OffsetLog b≈-0.127201 [neg_D8R] ...\n","Fitting OffsetLog b≈-0.0019837 [neg_D8F_rev] ...\n","Fitting OffsetLog b≈-0.140873 [neg_D8R_rev] ...\n","Fitting OffsetLog b≈0.0123628 [D9F] ...\n","Fitting OffsetLog b≈0.112637 [D9R] ...\n","Fitting OffsetLog b≈0.0013887 [D9F_rev] ...\n","Fitting OffsetLog b≈0.123611 [D9R_rev] ...\n","Fitting OffsetLog b≈-0.0123628 [neg_D9F] ...\n","Fitting OffsetLog b≈-0.112637 [neg_D9R] ...\n","Fitting OffsetLog b≈-0.0013887 [neg_D9F_rev] ...\n","Fitting OffsetLog b≈-0.123611 [neg_D9R_rev] ...\n","Fitting OffsetLog b≈0.0100101 [D10F] ...\n","Fitting OffsetLog b≈0.101101 [D10R] ...\n","Fitting OffsetLog b≈0.00101001 [D10F_rev] ...\n","Fitting OffsetLog b≈0.110101 [D10R_rev] ...\n","Fitting OffsetLog b≈-0.0100101 [neg_D10F] ...\n","Fitting OffsetLog b≈-0.101101 [neg_D10R] ...\n","Fitting OffsetLog b≈-0.00101001 [neg_D10F_rev] ...\n","Fitting OffsetLog b≈-0.110101 [neg_D10R_rev] ...\n","Fitting OffsetLog b≈0.00694849 [D12F] ...\n","Fitting OffsetLog b≈0.0839606 [D12R] ...\n","Fitting OffsetLog b≈0.000582725 [D12F_rev] ...\n","Fitting OffsetLog b≈0.0903264 [D12R_rev] ...\n","Fitting OffsetLog b≈-0.00694849 [neg_D12F] ...\n","Fitting OffsetLog b≈-0.0839606 [neg_D12R] ...\n","Fitting OffsetLog b≈-0.000582725 [neg_D12F_rev] ...\n","Fitting OffsetLog b≈-0.0903264 [neg_D12R_rev] ...\n","Fitting OffsetLog b≈0.98999 [OneMinus_D10F] ...\n","Fitting OffsetLog b≈-0.98999 [neg_OneMinus_D10F] ...\n","Fitting OffsetLog b≈0.290197 [BinF] ...\n","Fitting OffsetLog b≈0.709803 [BinR] ...\n","Fitting OffsetLog b≈-0.290197 [neg_BinF] ...\n","Fitting OffsetLog b≈-0.709803 [neg_BinR] ...\n","Fitting OffsetLog (fit b) ...\n","Saved figure: /content/out/hubble_Union2.1.png\n","\n","Wrote results: /content/out/results_summary.csv\n","\n","Primary verdict rule: rank by reduced χ² and ΔAIC (≤ 2 ≈ indistinguishable). R² is descriptive only.\n","Akaike weight ~ relative model support; evidence ratio is vs best-in-dataset = 1.0.\n","\n","Top models — Union2.1\n"]},{"output_type":"display_data","data":{"text/plain":["     dataset                                    model  red_chi2         AIC  \\\n","0   Union2.1                                     ΛCDM  0.972710 -233.480557   \n","1   Union2.1                                  Const‑w  0.972710 -233.480557   \n","2   Union2.1                                    w0–wₐ  0.972710 -233.480557   \n","90  Union2.1      OffsetLog b≈0.98999 [OneMinus_D10F]  0.979926 -229.310078   \n","96  Union2.1                        OffsetLog (fit b)  0.981020 -227.658855   \n","93  Union2.1              OffsetLog b≈0.709803 [BinR]  1.084445 -168.898089   \n","45  Union2.1  ScaleLog c≈-0.98999 [neg_OneMinus_D10F]  1.304736  -41.569659   \n","49  Union2.1          ScaleLog c≈-0.709803 [neg_BinR]  1.450802   42.856384   \n","48  Union2.1          ScaleLog c≈-0.290197 [neg_BinF]  1.759130  221.069724   \n","11  Union2.1       ScaleLog c≈-0.163692 [neg_D7R_rev]  1.870742  285.581730   \n","9   Union2.1           ScaleLog c≈-0.146198 [neg_D7R]  1.886799  294.862678   \n","19  Union2.1       ScaleLog c≈-0.140873 [neg_D8R_rev]  1.891715  297.704348   \n","\n","     delta_AIC  akaike_weight  evidence_ratio_vs_best         BIC   delta_BIC  \n","0     0.000000       0.314593                1.000000 -224.754501    0.000000  \n","1     0.000000       0.314593                1.000000 -224.754501    0.000000  \n","2     0.000000       0.314593                1.000000 -224.754501    0.000000  \n","90    4.170480       0.039097                0.124277 -220.584021    4.170480  \n","96    5.821702       0.017123                0.054429 -214.569771   10.184730  \n","93   64.582469       0.000000                0.000000 -160.172032   64.582469  \n","45  191.910899       0.000000                0.000000  -32.843602  191.910899  \n","49  276.336942       0.000000                0.000000   51.582441  276.336942  \n","48  454.550281       0.000000                0.000000  229.795780  454.550281  \n","11  519.062288       0.000000                0.000000  294.307787  519.062288  \n","9   528.343236       0.000000                0.000000  303.588735  528.343236  \n","19  531.184905       0.000000                0.000000  306.430404  531.184905  "],"text/html":["\n","  <div id=\"df-178360f6-e8ae-46c0-9b2d-7d779bc72c3f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dataset</th>\n","      <th>model</th>\n","      <th>red_chi2</th>\n","      <th>AIC</th>\n","      <th>delta_AIC</th>\n","      <th>akaike_weight</th>\n","      <th>evidence_ratio_vs_best</th>\n","      <th>BIC</th>\n","      <th>delta_BIC</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Union2.1</td>\n","      <td>ΛCDM</td>\n","      <td>0.972710</td>\n","      <td>-233.480557</td>\n","      <td>0.000000</td>\n","      <td>0.314593</td>\n","      <td>1.000000</td>\n","      <td>-224.754501</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Union2.1</td>\n","      <td>Const‑w</td>\n","      <td>0.972710</td>\n","      <td>-233.480557</td>\n","      <td>0.000000</td>\n","      <td>0.314593</td>\n","      <td>1.000000</td>\n","      <td>-224.754501</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Union2.1</td>\n","      <td>w0–wₐ</td>\n","      <td>0.972710</td>\n","      <td>-233.480557</td>\n","      <td>0.000000</td>\n","      <td>0.314593</td>\n","      <td>1.000000</td>\n","      <td>-224.754501</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>90</th>\n","      <td>Union2.1</td>\n","      <td>OffsetLog b≈0.98999 [OneMinus_D10F]</td>\n","      <td>0.979926</td>\n","      <td>-229.310078</td>\n","      <td>4.170480</td>\n","      <td>0.039097</td>\n","      <td>0.124277</td>\n","      <td>-220.584021</td>\n","      <td>4.170480</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>Union2.1</td>\n","      <td>OffsetLog (fit b)</td>\n","      <td>0.981020</td>\n","      <td>-227.658855</td>\n","      <td>5.821702</td>\n","      <td>0.017123</td>\n","      <td>0.054429</td>\n","      <td>-214.569771</td>\n","      <td>10.184730</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>Union2.1</td>\n","      <td>OffsetLog b≈0.709803 [BinR]</td>\n","      <td>1.084445</td>\n","      <td>-168.898089</td>\n","      <td>64.582469</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-160.172032</td>\n","      <td>64.582469</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>Union2.1</td>\n","      <td>ScaleLog c≈-0.98999 [neg_OneMinus_D10F]</td>\n","      <td>1.304736</td>\n","      <td>-41.569659</td>\n","      <td>191.910899</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-32.843602</td>\n","      <td>191.910899</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>Union2.1</td>\n","      <td>ScaleLog c≈-0.709803 [neg_BinR]</td>\n","      <td>1.450802</td>\n","      <td>42.856384</td>\n","      <td>276.336942</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>51.582441</td>\n","      <td>276.336942</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>Union2.1</td>\n","      <td>ScaleLog c≈-0.290197 [neg_BinF]</td>\n","      <td>1.759130</td>\n","      <td>221.069724</td>\n","      <td>454.550281</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>229.795780</td>\n","      <td>454.550281</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Union2.1</td>\n","      <td>ScaleLog c≈-0.163692 [neg_D7R_rev]</td>\n","      <td>1.870742</td>\n","      <td>285.581730</td>\n","      <td>519.062288</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>294.307787</td>\n","      <td>519.062288</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Union2.1</td>\n","      <td>ScaleLog c≈-0.146198 [neg_D7R]</td>\n","      <td>1.886799</td>\n","      <td>294.862678</td>\n","      <td>528.343236</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>303.588735</td>\n","      <td>528.343236</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Union2.1</td>\n","      <td>ScaleLog c≈-0.140873 [neg_D8R_rev]</td>\n","      <td>1.891715</td>\n","      <td>297.704348</td>\n","      <td>531.184905</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>306.430404</td>\n","      <td>531.184905</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-178360f6-e8ae-46c0-9b2d-7d779bc72c3f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-178360f6-e8ae-46c0-9b2d-7d779bc72c3f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-178360f6-e8ae-46c0-9b2d-7d779bc72c3f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-83abef0a-f296-4c26-a5c3-b6ecae74e33e\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83abef0a-f296-4c26-a5c3-b6ecae74e33e')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-83abef0a-f296-4c26-a5c3-b6ecae74e33e button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \")\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Union2.1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"ScaleLog c\\u2248-0.146198 [neg_D7R]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"red_chi2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.40481227731586783,\n        \"min\": 0.97271,\n        \"max\": 1.891715,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.886799\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AIC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 233.8986063865754,\n        \"min\": -233.480557,\n        \"max\": 297.704348,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          294.862678\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delta_AIC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 233.89860650178645,\n        \"min\": 0.0,\n        \"max\": 531.184905,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          528.343236\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"akaike_weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13993338441696596,\n        \"min\": 0.0,\n        \"max\": 0.314593,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.039097\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"evidence_ratio_vs_best\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4448077183390254,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.124277\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BIC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 233.54758575630578,\n        \"min\": -224.754501,\n        \"max\": 306.430404,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          303.588735\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delta_BIC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 233.54758575630578,\n        \"min\": 0.0,\n        \"max\": 531.184905,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          528.343236\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["# === Binary-augmented supernova cosmology test (with LOESS & Akaike weights) — one-shot Colab cell ===\n","# - Fair SN pipeline: analytic Δ (intercept) per model, Ωm fit for all, covariance when available.\n","# - Baselines: ΛCDM, constant-w, w0–wa.  Binary families: ScaleLog, OffsetLog, OffsetLog (fit b).\n","# - Fibonacci word + complement + reverse-order; base-B digit maps for B in {7,8,9,10,12}; binary fractions.\n","# - Residual LOESS trends; AIC/BIC, ΔAIC/ΔBIC, Akaike weights; optional Pantheon CSV.\n","# - No seaborn; matplotlib only; one chart per dataset with default colors.\n","\n","# 0) Quiet installs (safe for Colab)\n","import sys, subprocess, importlib\n","def _pip(pkg): subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n","for pkg in [\"numpy\", \"pandas\", \"matplotlib\", \"scipy\", \"requests\", \"statsmodels\"]:\n","    try: importlib.import_module(pkg)\n","    except Exception: _pip(pkg)\n","\n","# 1) Imports\n","import os, io, math, warnings, numpy as np, pandas as pd, matplotlib.pyplot as plt\n","from dataclasses import dataclass, field\n","from typing import Dict, Tuple, Optional, List\n","warnings.filterwarnings(\"ignore\")\n","from scipy.optimize import minimize\n","from statsmodels.nonparametric.smoothers_lowess import lowess\n","\n","# --------------------------- Utilities ---------------------------\n","\n","def http_get(url: str, timeout: int = 40) -> Optional[bytes]:\n","    import requests\n","    try:\n","        r = requests.get(url, timeout=timeout)\n","        return r.content if r.status_code == 200 else None\n","    except Exception:\n","        return None\n","\n","def safe_logdet(C: np.ndarray) -> float:\n","    sign, logdet = np.linalg.slogdet(C)\n","    if not np.isfinite(logdet) or sign <= 0:\n","        eps = 1e-12 * float(np.mean(np.diag(C)))\n","        C = C + eps * np.eye(C.shape[0])\n","        sign, logdet = np.linalg.slogdet(C)\n","    return float(logdet)\n","\n","def analytic_delta_chi2(mu_obs: np.ndarray, mu_model: np.ndarray, Cinv: np.ndarray) -> Tuple[float, float]:\n","    \"\"\"Best-fit intercept Δ and minimal chi^2 for residuals r = mu_obs - (mu_model + Δ).\"\"\"\n","    r = mu_obs - mu_model\n","    u = np.ones_like(r)\n","    A = float(u @ (Cinv @ u))\n","    B = float(u @ (Cinv @ r))\n","    delta_star = B / A\n","    chi2_min = float(r @ (Cinv @ r) - (B**2)/A)\n","    return chi2_min, delta_star\n","\n","def r_squared(y: np.ndarray, yhat: np.ndarray) -> float:\n","    ss_res = float(np.sum((y - yhat)**2))\n","    ss_tot = float(np.sum((y - np.mean(y))**2))\n","    return 1.0 - ss_res/ss_tot\n","\n","def aic_bic(chi2_min: float, C: np.ndarray, k_params: int) -> Tuple[float, float, float]:\n","    N = C.shape[0]\n","    logdet = safe_logdet(C)\n","    logL = -0.5 * (chi2_min + logdet + N * math.log(2*math.pi))\n","    AIC = 2*k_params - 2*logL\n","    BIC = k_params*math.log(N) - 2*logL\n","    return float(logL), float(AIC), float(BIC)\n","\n","# --------------------------- Fibonacci word & constants ---------------------------\n","# Follows your \"decimal-digit translation\" (0.b1b2...) and complement facts. :contentReference[oaicite:2]{index=2} :contentReference[oaicite:3]{index=3}\n","\n","def fib_bits(N: int) -> str:\n","    \"\"\"First N bits of the Fibonacci word (morphism 0->01, 1->0).\"\"\"\n","    s = \"0\"\n","    while len(s) < N:\n","        s = \"\".join(\"01\" if ch == \"0\" else \"0\" for ch in s)\n","    return s[:N]\n","\n","def complement_bits(bits: str) -> str:\n","    return \"\".join(\"1\" if b == \"0\" else \"0\" for b in bits)\n","\n","def reverse_bits(bits: str) -> str:\n","    return bits[::-1]\n","\n","def base_digits_value(bits: str, base: int) -> float:\n","    \"\"\"Interpret bits as 0.b1 b2 ... in base 'base' (digits restricted to {0,1}).\"\"\"\n","    acc = 0.0\n","    inv = 1.0 / base\n","    for b in bits[::-1]:  # Horner from the right\n","        acc = (acc + (1.0 if b == \"1\" else 0.0)) * inv\n","    return acc\n","\n","def binary_fraction_value(bits: str) -> float:\n","    \"\"\"Interpret bits as a binary fraction: sum b_i 2^{-i}.\"\"\"\n","    acc = 0.0\n","    for b in bits[::-1]:\n","        acc = (acc + (1.0 if b == \"1\" else 0.0)) * 0.5\n","    return acc\n","\n","def make_binary_constants(n_digits: int = 200, bases=(7,8,9,10,12)) -> Dict[str, float]:\n","    \"\"\"Produce DF/DR for B∈bases, plus reverse-order variants and binary-fraction values (and negatives).\"\"\"\n","    F = fib_bits(n_digits)\n","    R = complement_bits(F)              # Rabbit/complement\n","    F_rev = reverse_bits(F)\n","    R_rev = reverse_bits(R)\n","\n","    consts = {}\n","    for B in bases:\n","        consts[f\"D{B}F\"]      = base_digits_value(F, B)\n","        consts[f\"D{B}R\"]      = base_digits_value(R, B)\n","        consts[f\"D{B}F_rev\"]  = base_digits_value(F_rev, B)\n","        consts[f\"D{B}R_rev\"]  = base_digits_value(R_rev, B)\n","        # negatives\n","        consts[f\"neg_D{B}F\"]      = -consts[f\"D{B}F\"]\n","        consts[f\"neg_D{B}R\"]      = -consts[f\"D{B}R\"]\n","        consts[f\"neg_D{B}F_rev\"]  = -consts[f\"D{B}F_rev\"]\n","        consts[f\"neg_D{B}R_rev\"]  = -consts[f\"D{B}R_rev\"]\n","    # 1 - DF for base-10 (explicit in your request)\n","    consts[\"OneMinus_D10F\"] = 1.0 - consts[\"D10F\"]\n","    consts[\"neg_OneMinus_D10F\"] = -consts[\"OneMinus_D10F\"]\n","\n","    # Binary fractions\n","    BF = binary_fraction_value(F)\n","    BR = 1.0 - BF\n","    consts[\"BinF\"] = BF\n","    consts[\"BinR\"] = BR\n","    consts[\"neg_BinF\"] = -BF\n","    consts[\"neg_BinR\"] = -BR\n","\n","    return consts\n","\n","# --------------------------- Cosmology models ---------------------------\n","\n","@dataclass\n","class CosmoModel:\n","    name: str\n","    fit_omegam: bool\n","    params: Dict[str, float] = field(default_factory=dict)\n","    def predict_mu(self, z: np.ndarray, H0: float = 70.0) -> np.ndarray:\n","        raise NotImplementedError\n","\n","def E2_LCDM(z: np.ndarray, Om: float) -> np.ndarray:\n","    return Om*(1+z)**3 + (1-Om)\n","\n","def E2_constw(z: np.ndarray, Om: float, w0: float) -> np.ndarray:\n","    return Om*(1+z)**3 + (1-Om)*(1+z)**(3*(1+w0))\n","\n","def E2_w0wa(z: np.ndarray, Om: float, w0: float, wa: float) -> np.ndarray:\n","    g = (1+z)**(3*(1+w0+wa)) * np.exp(-3*wa*z/(1+z))\n","    return Om*(1+z)**3 + (1-Om)*g\n","\n","def E2_binary(z: np.ndarray, Om: float) -> np.ndarray:\n","    ln1pz = np.log(1+z)\n","    g = (1+z)**3 * np.exp((3.0/(2.0*math.log(2.0)))*(ln1pz**2))\n","    return Om*(1+z)**3 + (1-Om)*g\n","\n","def E2_scale_log(z: np.ndarray, Om: float, c: float) -> np.ndarray:\n","    ln1pz = np.log(1+z)\n","    g = (1+z)**3 * np.exp((3.0*c/(2.0*math.log(2.0)))*(ln1pz**2))\n","    return Om*(1+z)**3 + (1-Om)*g\n","\n","def E2_offset_log(z: np.ndarray, Om: float, b: float) -> np.ndarray:\n","    ln1pz = np.log(1+z)\n","    g = (1+z)**(3*(1.0-b)) * np.exp((3.0/(2.0*math.log(2.0)))*(ln1pz**2))\n","    return Om*(1+z)**3 + (1-Om)*g\n","\n","def distance_modulus(z: np.ndarray, E2_func, H0: float, Om: float, **kwargs) -> np.ndarray:\n","    zmax = float(np.max(z))\n","    z_grid = np.linspace(0.0, max(zmax, 1e-6), 4000)\n","    if E2_func is E2_constw:\n","        w0 = kwargs.get(\"w0\", -1.0); E2_grid = E2_constw(z_grid, Om, w0)\n","    elif E2_func is E2_w0wa:\n","        w0 = kwargs.get(\"w0\", -1.0); wa = kwargs.get(\"wa\", 0.0); E2_grid = E2_w0wa(z_grid, Om, w0, wa)\n","    elif E2_func is E2_binary:\n","        E2_grid = E2_binary(z_grid, Om)\n","    elif E2_func is E2_scale_log:\n","        c = kwargs.get(\"c\", 1.0); E2_grid = E2_scale_log(z_grid, Om, c)\n","    elif E2_func is E2_offset_log:\n","        b = kwargs.get(\"b\", 0.0); E2_grid = E2_offset_log(z_grid, Om, b)\n","    else:\n","        E2_grid = E2_LCDM(z_grid, Om)\n","\n","    E_grid = np.sqrt(np.maximum(E2_grid, 1e-30))\n","    invE = 1.0/E_grid\n","    Dc_grid = np.zeros_like(z_grid)\n","    Dc_grid[1:] = np.cumsum(0.5*(invE[1:]+invE[:-1])*(z_grid[1:]-z_grid[:-1]))\n","    c_km_s = 299792.458\n","    Dc_grid *= c_km_s/ H0\n","    Dc = np.interp(z, z_grid, Dc_grid)\n","    Dl = (1+z)*Dc\n","    mu = 5.0*np.log10(np.maximum(Dl, 1e-30)) + 25.0\n","    return mu\n","\n","class LCDM(CosmoModel):\n","    def predict_mu(self, z, H0=70.0):\n","        Om = self.params.get(\"Omega_m\", 0.3)\n","        return distance_modulus(z, E2_LCDM, H0, Om)\n","\n","class ConstW(CosmoModel):\n","    def predict_mu(self, z, H0=70.0):\n","        Om = self.params.get(\"Omega_m\", 0.3)\n","        w0 = self.params.get(\"w0\", -1.0)\n","        return distance_modulus(z, E2_constw, H0, Om, w0=w0)\n","\n","class W0Wa(CosmoModel):\n","    def predict_mu(self, z, H0=70.0):\n","        Om = self.params.get(\"Omega_m\", 0.3)\n","        w0 = self.params.get(\"w0\", -1.0); wa = self.params.get(\"wa\", 0.0)\n","        return distance_modulus(z, E2_w0wa, H0, Om, w0=w0, wa=wa)\n","\n","class BinaryW(CosmoModel):\n","    def predict_mu(self, z, H0=70.0):\n","        Om = self.params.get(\"Omega_m\", 0.3)\n","        return distance_modulus(z, E2_binary, H0, Om)\n","\n","class ScaleLog(CosmoModel):\n","    def predict_mu(self, z, H0=70.0):\n","        Om = self.params.get(\"Omega_m\", 0.3); c = self.params.get(\"c\", 1.0)\n","        return distance_modulus(z, E2_scale_log, H0, Om, c=c)\n","\n","class OffsetLog(CosmoModel):\n","    def predict_mu(self, z, H0=70.0):\n","        Om = self.params.get(\"Omega_m\", 0.3); b = self.params.get(\"b\", 0.0)\n","        return distance_modulus(z, E2_offset_log, H0, Om, b=b)\n","\n","class OffsetLogFitB(CosmoModel):\n","    \"\"\"One-parameter extension: fit {Omega_m, b} (pre‑registered).\"\"\"\n","    def predict_mu(self, z, H0=70.0):\n","        Om = self.params.get(\"Omega_m\", 0.3); b = self.params.get(\"b\", 1.0)\n","        return distance_modulus(z, E2_offset_log, H0, Om, b=b)\n","\n","# --------------------------- Data loaders (covariance attempts) ---------------------------\n","\n","def _try_load_cov_from_text(content: bytes, N: int) -> Optional[np.ndarray]:\n","    try:\n","        lines = [ln for ln in content.decode(\"utf-8\", errors=\"ignore\").splitlines() if ln.strip() and not ln.strip().startswith(\"#\")]\n","        arr = []\n","        for ln in lines:\n","            try: arr.append([float(x) for x in ln.split()])\n","            except Exception: pass\n","        M = np.array(arr, dtype=float)\n","        if M.shape == (N, N): return M\n","        flat = M.reshape(-1); t = flat.size; n = int((np.sqrt(1+8*t)-1)//2)\n","        if n == N and n*(n+1)//2 == t:\n","            C = np.zeros((N, N), float); k = 0\n","            for i in range(N):\n","                for j in range(i, N):\n","                    C[i, j] = C[j, i] = flat[k]; k += 1\n","            return C\n","        return None\n","    except Exception:\n","        return None\n","\n","def load_union21(use_cov: bool=True) -> Tuple[pd.DataFrame, np.ndarray]:\n","    tbl = http_get(\"https://supernova.lbl.gov/Union/figures/SCPUnion2.1_mu_vs_z.txt\")\n","    if tbl is None: raise RuntimeError(\"Union2.1 table download failed.\")\n","    rows = []\n","    for ln in tbl.decode(\"utf-8\").splitlines():\n","        if ln.startswith(\"#\") or not ln.strip(): continue\n","        p = ln.split()\n","        if len(p) >= 4: rows.append((float(p[1]), float(p[2]), float(p[3])))\n","    df = pd.DataFrame(rows, columns=[\"z\",\"mu\",\"mu_err\"]).sort_values(\"z\").reset_index(drop=True)\n","    N = len(df); C = None\n","    if use_cov:\n","        stat = http_get(\"https://supernova.lbl.gov/Union/figures/SCPUnion2.1_covmat_stat.txt\")\n","        sysm = http_get(\"https://supernova.lbl.gov/Union/figures/SCPUnion2.1_covmat_sys.txt\")\n","        if stat is not None and sysm is not None:\n","            C_stat = _try_load_cov_from_text(stat, N); C_sys = _try_load_cov_from_text(sysm, N)\n","            if C_stat is not None and C_sys is not None: C = C_stat + C_sys\n","    if C is None: C = np.diag(np.maximum(df[\"mu_err\"].values, 1e-9)**2)\n","    return df, C\n","\n","def load_jla(use_cov: bool=True) -> Tuple[pd.DataFrame, np.ndarray]:\n","    tbl = http_get(\"http://supernovae.in2p3.fr/sdss_snls_jla/jla_mub.txt\")\n","    if tbl is None: raise RuntimeError(\"JLA mub download failed.\")\n","    rows = []\n","    for ln in tbl.decode(\"utf-8\").splitlines():\n","        if ln.startswith(\"#\") or not ln.strip(): continue\n","        p = ln.split()\n","        if len(p) >= 3: rows.append((float(p[0]), float(p[1]), float(p[2])))\n","    df = pd.DataFrame(rows, columns=[\"z\",\"mu\",\"mu_err\"]).sort_values(\"z\").reset_index(drop=True)\n","    N = len(df); C = None\n","    if use_cov:\n","        for url in [\n","            \"http://supernovae.in2p3.fr/sdss_snls_jla/uncertainties/covmat_v6.dat\",\n","            \"http://supernovae.in2p3.fr/sdss_snls_jla/covmat_v6.dat\",\n","            \"http://supernovae.in2p3.fr/sdss_snls_jla/jla_cov_full.txt\",\n","        ]:\n","            blob = http_get(url)\n","            if blob is not None:\n","                M = _try_load_cov_from_text(blob, N)\n","                if M is not None: C = M; break\n","    if C is None: C = np.diag(np.maximum(df[\"mu_err\"].values, 1e-9)**2)\n","    return df, C\n","\n","def load_pantheon_from_csv(path_or_url: str) -> Tuple[pd.DataFrame, np.ndarray]:\n","    \"\"\"Minimal CSV hook. Provide a direct CSV URL/path with columns like z,mu,mu_err (zcmb/mb/dmu also recognized).\"\"\"\n","    if path_or_url.startswith(\"http\"):\n","        content = http_get(path_or_url)\n","        if content is None: raise RuntimeError(\"Pantheon CSV download failed.\")\n","        df = pd.read_csv(io.BytesIO(content))\n","    else:\n","        df = pd.read_csv(path_or_url)\n","    cols = list(df.columns)\n","    zcol = \"z\" if \"z\" in cols else \"zcmb\" if \"zcmb\" in cols else cols[0]\n","    mucol = \"mu\" if \"mu\" in cols else \"mb\" if \"mb\" in cols else cols[1]\n","    ecol = \"mu_err\" if \"mu_err\" in cols else \"dmu\" if \"dmu\" in cols else cols[2]\n","    out = df[[zcol, mucol, ecol]].copy()\n","    out.columns = [\"z\",\"mu\",\"mu_err\"]\n","    out = out.sort_values(\"z\").reset_index(drop=True)\n","    C = np.diag(np.maximum(out[\"mu_err\"].values, 1e-9)**2)\n","    return out, C\n","\n","# --------------------------- Fitting ---------------------------\n","\n","@dataclass\n","class FitResult:\n","    model: str\n","    dataset: str\n","    params: Dict[str, float]\n","    delta: float\n","    chi2: float\n","    dof: int\n","    red_chi2: float\n","    logL: float\n","    AIC: float\n","    BIC: float\n","    R2: float\n","    N: int\n","    tag: str\n","\n","def fit_model(model: CosmoModel, df: pd.DataFrame, C: np.ndarray, H0: float=70.0) -> FitResult:\n","    z, mu = df[\"z\"].values, df[\"mu\"].values\n","    N = len(z)\n","    jitter = 1e-10 * float(np.mean(np.diag(C)))\n","    C_use = C + jitter*np.eye(N)\n","    Cinv = np.linalg.inv(C_use)\n","\n","    # Parameter vector (Ωm + optional b)\n","    tag = model.name\n","    p0, bounds = [], []\n","    if model.fit_omegam:\n","        p0.append(model.params.get(\"Omega_m\", 0.3)); bounds.append((0.01, 0.99))\n","\n","    # allow fit of b in OffsetLogFitB\n","    if isinstance(model, OffsetLogFitB):\n","        p0.append(model.params.get(\"b\", 1.0)); bounds.append((-2.0, 2.0))  # wide, but bounded\n","\n","    def make_pred(theta):\n","        i = 0; pars = dict(model.params)\n","        if model.fit_omegam: pars[\"Omega_m\"] = float(theta[i]); i += 1\n","        if isinstance(model, OffsetLogFitB):\n","            pars[\"b\"] = float(theta[i]); i += 1\n","        mdl = type(model)(name=model.name, fit_omegam=model.fit_omegam, params=pars)\n","        return mdl.predict_mu(z, H0=H0), pars\n","\n","    def obj(theta):\n","        mu_pred, _ = make_pred(theta)\n","        chi2_min, _ = analytic_delta_chi2(mu_obs=mu, mu_model=mu_pred, Cinv=Cinv)\n","        return chi2_min\n","\n","    theta = np.array(p0, dtype=float)\n","    if len(p0) > 0:\n","        res = minimize(obj, x0=theta, bounds=bounds, method=\"L-BFGS-B\")\n","        theta = res.x\n","\n","    mu_pred, pars = make_pred(theta)\n","    chi2_min, delta = analytic_delta_chi2(mu_obs=mu, mu_model=mu_pred, Cinv=Cinv)\n","    k = len(theta) + 1  # +Δ\n","    dof = max(1, N - k)\n","    logL, AIC, BIC = aic_bic(chi2_min, C_use, k)\n","    R2 = r_squared(mu, mu_pred + delta)\n","\n","    return FitResult(\n","        model=model.name, dataset=\"\", params=pars, delta=float(delta),\n","        chi2=float(chi2_min), dof=int(dof), red_chi2=float(chi2_min/dof),\n","        logL=float(logL), AIC=float(AIC), BIC=float(BIC), R2=float(R2), N=N, tag=tag\n","    )\n","\n","# --------------------------- Plotting ---------------------------\n","\n","def panel_plot_with_loess(df: pd.DataFrame, lines: Dict[str, Dict[str, np.ndarray]], out_png: str, title_suffix=\"\"):\n","    z, mu, mu_err = df[\"z\"].values, df[\"mu\"].values, df[\"mu_err\"].values\n","    fig = plt.figure(figsize=(8, 10))\n","\n","    # Hubble diagram\n","    ax1 = fig.add_subplot(2, 1, 1)\n","    ax1.errorbar(z, mu, yerr=mu_err, fmt=\".\", alpha=0.5, markersize=3)\n","    for name, d in lines.items():\n","        ax1.plot(z, d[\"mu_pred\"] + d[\"delta\"])\n","    ax1.set_xlabel(\"Redshift z\"); ax1.set_ylabel(\"Distance modulus μ\")\n","    ax1.set_title(f\"Supernova Hubble diagram — {title_suffix}\"); ax1.grid(True, alpha=0.3)\n","    ax1.legend(list(lines.keys()))\n","\n","    # Residuals + LOESS (LOWESS)\n","    ax2 = fig.add_subplot(2, 1, 2)\n","    for name, d in lines.items():\n","        res = mu - (d[\"mu_pred\"] + d[\"delta\"])\n","        ax2.scatter(z, res, s=6, alpha=0.5, label=name)\n","        # LOWESS trend\n","        try:\n","            z_s, res_s = z.copy(), res.copy()\n","            order = np.argsort(z_s)\n","            smooth = lowess(res_s[order], z_s[order], frac=0.25, it=0, return_sorted=True)\n","            ax2.plot(smooth[:,0], smooth[:,1], linewidth=2, alpha=0.9)\n","        except Exception:\n","            pass\n","    ax2.axhline(0.0, linestyle=\"--\")\n","    ax2.set_xlabel(\"Redshift z\"); ax2.set_ylabel(\"Residual μ_obs − μ_model\")\n","    ax2.set_title(\"Residuals (after Δ fit) with LOESS trend\"); ax2.grid(True, alpha=0.3)\n","    ax2.legend(list(lines.keys()))\n","    fig.tight_layout(); fig.savefig(out_png, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n","\n","# --------------------------- Runner ---------------------------\n","\n","def run_everything(\n","    outdir=\"/content/out\",\n","    datasets=(\"union\",\"jla\"),  # optionally add \"pantheon_csv:<url>\"\n","    use_cov=True,\n","    include_baselines=True,\n","    include_binary_original=True,\n","    include_scale=True,\n","    include_offset=True,\n","    include_offset_fit_b=True,     # fit b as one extra parameter\n","    H0=70.0,\n","    n_digits=200\n","):\n","    os.makedirs(outdir, exist_ok=True)\n","\n","    # Load datasets\n","    ds_list = []\n","    for token in datasets:\n","        try:\n","            if token.lower()==\"union\": ds_list.append((\"Union2.1\",)+load_union21(use_cov=use_cov))\n","            elif token.lower()==\"jla\": ds_list.append((\"JLA\",)+load_jla(use_cov=use_cov))\n","            elif token.lower().startswith(\"pantheon_csv:\"):\n","                path = token.split(\":\",1)[1]\n","                ds_list.append((\"Pantheon (CSV)\",)+load_pantheon_from_csv(path))\n","        except Exception as e:\n","            print(f\"[WARN] Failed to load {token}: {e}\")\n","    if not ds_list:\n","        print(\"[ERROR] No datasets loaded. Exiting.\")\n","        return\n","\n","    # Binary constants (F, complement, reverse; bases 7,8,9,10,12; + negatives; + binary fractions)\n","    consts = make_binary_constants(n_digits=n_digits, bases=(7,8,9,10,12))\n","    print(\"\\n=== Binary constants (first few) ===\")\n","    for k in list(consts.keys())[:12]:\n","        print(f\"{k:>18} = {consts[k]:.18g}\")\n","    print(f\"... total constants: {len(consts)}\")\n","\n","    # Build model list\n","    models: List[CosmoModel] = []\n","    if include_baselines:\n","        models += [\n","            LCDM(name=\"ΛCDM\", fit_omegam=True, params={\"Omega_m\":0.3}),\n","            ConstW(name=\"Const‑w\", fit_omegam=True, params={\"Omega_m\":0.3,\"w0\":-1.0}),\n","            W0Wa(name=\"w0–wₐ\", fit_omegam=True, params={\"Omega_m\":0.3,\"w0\":-1.0,\"wa\":0.0}),\n","        ]\n","    if include_binary_original:\n","        models.append(BinaryW(name=\"Binary w(a)=−log₂a\", fit_omegam=True, params={\"Omega_m\":0.3}))\n","    if include_scale:\n","        for key, val in consts.items():\n","            models.append(ScaleLog(name=f\"ScaleLog c≈{val:.6g} [{key}]\", fit_omegam=True,\n","                                   params={\"Omega_m\":0.3, \"c\": val}))\n","    if include_offset:\n","        for key, val in consts.items():\n","            models.append(OffsetLog(name=f\"OffsetLog b≈{val:.6g} [{key}]\", fit_omegam=True,\n","                                    params={\"Omega_m\":0.3, \"b\": val}))\n","    if include_offset_fit_b:\n","        models.append(OffsetLogFitB(name=\"OffsetLog (fit b)\", fit_omegam=True, params={\"Omega_m\":0.3, \"b\": 1.0}))\n","\n","    # Fit\n","    rows = []\n","    for (ds_name, df, C) in ds_list:\n","        print(f\"\\n=== DATASET: {ds_name} (N={len(df)}) ===\")\n","        z = df[\"z\"].values\n","\n","        for mdl in models:\n","            print(f\"Fitting {mdl.name} ...\")\n","            r = fit_model(mdl, df, C, H0=H0); r.dataset = ds_name\n","            rows.append({\n","                \"dataset\": ds_name, \"model\": mdl.name,\n","                **{f\"param_{k}\": v for k, v in r.params.items()},\n","                \"delta\": r.delta, \"chi2\": r.chi2, \"dof\": r.dof, \"red_chi2\": r.red_chi2,\n","                \"logL\": r.logL, \"AIC\": r.AIC, \"BIC\": r.BIC, \"R2\": r.R2, \"N\": r.N, \"tag\": r.tag\n","            })\n","\n","        # Choose up to 6 lines to plot: ΛCDM, const‑w, original binary, best ScaleLog, best OffsetLog, OffsetLog(fit b)\n","        df_res = pd.DataFrame(rows)\n","        df_ds = df_res[df_res[\"dataset\"]==ds_name].copy()\n","\n","        def pick_best_by_prefix(prefix):\n","            sub = df_ds[df_ds[\"model\"].str.startswith(prefix)]\n","            return None if sub.empty else sub.sort_values(\"AIC\").iloc[0]\n","\n","        picks = []\n","        for label in [\"ΛCDM\",\"Const‑w\",\"Binary w(a)=−log₂a\"]:\n","            got = df_ds[df_ds[\"model\"]==label]\n","            if not got.empty: picks.append(got.iloc[0])\n","        for pfx in [\"ScaleLog\",\"OffsetLog b\",\"OffsetLog (fit b)\"]:\n","            got = pick_best_by_prefix(pfx)\n","            if got is not None: picks.append(got)\n","\n","        lines = {}\n","        for r in picks:\n","            name = r[\"model\"]\n","            Om = float(r.get(\"param_Omega_m\", 0.3))\n","            if name.startswith(\"ScaleLog\"):\n","                c = float(r.get(\"param_c\", 1.0)); mdl = ScaleLog(name=name, fit_omegam=True, params={\"Omega_m\":Om, \"c\":c})\n","            elif name.startswith(\"OffsetLog b\"):\n","                b = float(r.get(\"param_b\", 1.0)); mdl = OffsetLog(name=name, fit_omegam=True, params={\"Omega_m\":Om, \"b\":b})\n","            elif name.startswith(\"OffsetLog (fit b)\"):\n","                b = float(r.get(\"param_b\", 1.0)); mdl = OffsetLogFitB(name=name, fit_omegam=True, params={\"Omega_m\":Om, \"b\":b})\n","            elif name == \"ΛCDM\":\n","                mdl = LCDM(name=name, fit_omegam=True, params={\"Omega_m\":Om})\n","            elif name == \"Const‑w\":\n","                w0 = float(r.get(\"param_w0\",-1.0)); mdl = ConstW(name=name, fit_omegam=True, params={\"Omega_m\":Om,\"w0\":w0})\n","            elif name == \"Binary w(a)=−log₂a\":\n","                mdl = BinaryW(name=name, fit_omegam=True, params={\"Omega_m\":Om})\n","            else:\n","                continue\n","            mu_pred = mdl.predict_mu(z, H0=H0)\n","            lines[name] = {\"mu_pred\": mu_pred, \"delta\": float(r[\"delta\"])}\n","\n","        if lines: # Only plot if there are lines to plot\n","            out_png = os.path.join(outdir, f\"hubble_{ds_name.replace(' ','_')}.png\")\n","            panel_plot_with_loess(df, lines, out_png, title_suffix=ds_name)\n","            print(f\"Saved figure: {out_png}\")\n","\n","\n","    if not rows: # Check if any data was processed successfully\n","      print(\"[ERROR] No results were generated.\")\n","      return\n","\n","    # Results table with ΔAIC/ΔBIC and Akaike weights\n","    df_all = pd.DataFrame(rows)\n","    if not df_all.empty:\n","        df_all[\"rank_by_AIC\"] = df_all.groupby(\"dataset\")[\"AIC\"].rank(method=\"min\")\n","        df_all[\"delta_AIC\"]  = df_all[\"AIC\"] - df_all.groupby(\"dataset\")[\"AIC\"].transform(\"min\")\n","        df_all[\"rank_by_BIC\"] = df_all.groupby(\"dataset\")[\"BIC\"].rank(method=\"min\")\n","        df_all[\"delta_BIC\"]  = df_all[\"BIC\"] - df_all.groupby(\"dataset\")[\"BIC\"].transform(\"min\")\n","\n","        # Akaike weights per dataset\n","        def akaike_weights(group):\n","            deltas = group[\"delta_AIC\"].values\n","            w = np.exp(-0.5*deltas)\n","            w = w / np.sum(w)\n","            return pd.Series(w, index=group.index, name=\"akaike_weight\")\n","\n","        # Apply the akaike_weights function and assign the results correctly\n","        # Using a list comprehension to handle potential empty groups more robustly\n","        akaike_weights_list = [\n","            akaike_weights(group) for _, group in df_all.groupby(\"dataset\")\n","        ]\n","        if akaike_weights_list:\n","            df_all[\"akaike_weight\"] = pd.concat(akaike_weights_list)\n","            # Evidence ratio vs best (best has weight 1.0)\n","            df_all[\"evidence_ratio_vs_best\"] = df_all.groupby(\"dataset\")[\"akaike_weight\"].transform(lambda x: x / x.max())\n","        else:\n","             df_all[\"akaike_weight\"] = np.nan\n","             df_all[\"evidence_ratio_vs_best\"] = np.nan\n","\n","\n","    out_csv = os.path.join(outdir, \"results_summary.csv\")\n","    df_all.to_csv(out_csv, index=False)\n","    print(f\"\\nWrote results: {out_csv}\")\n","    print(\"\\nPrimary verdict rule: rank by reduced χ² and ΔAIC (≤ 2 ≈ indistinguishable). R² is descriptive only.\")\n","    print(\"Akaike weight ~ relative model support; evidence ratio is vs best-in-dataset = 1.0.\")\n","\n","    # Show top-12 by AIC per dataset\n","    show_cols = [\"dataset\",\"model\",\"red_chi2\",\"AIC\",\"delta_AIC\",\"akaike_weight\",\"evidence_ratio_vs_best\",\"BIC\",\"delta_BIC\"]\n","    try:\n","        from IPython.display import display\n","        for ds in df_all[\"dataset\"].unique():\n","            print(f\"\\nTop models — {ds}\")\n","            display(df_all[df_all[\"dataset\"]==ds].sort_values(\"AIC\").head(12)[show_cols].round(6))\n","    except Exception:\n","        for ds in df_all[\"dataset\"].unique():\n","            print(f\"\\nTop models — {ds}\")\n","            print(df_all[df_all[\"dataset\"]==ds].sort_values(\"AIC\").head(12)[show_cols].round(6))\n","\n","# --------------------------- Run with robust defaults ---------------------------\n","run_everything(\n","    outdir=\"/content/out\",\n","    datasets=(\"union\",\"jla\"),      # add \"pantheon_csv:<direct_csv_url>\" if you have it\n","    use_cov=True,                  # attempt full covariance; falls back to diagonal\n","    include_baselines=True,\n","    include_binary_original=True,\n","    include_scale=True,\n","    include_offset=True,\n","    include_offset_fit_b=True,     # one-parameter offset family (fits b)\n","    H0=70.0,\n","    n_digits=200                   # digits used to build constants\n",")"]}]}