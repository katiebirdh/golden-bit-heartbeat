{"cells":[{"cell_type":"markdown","id":"0efa0869","metadata":{"id":"0efa0869"},"source":["# Autoscan Notebook v1\n","*Last updated 2025-07-14*\n","\n","**Purpose**\n","This standalone notebook lets you:\n","1. Upload two Excel files (raw & ops) *or* use autogenerated dummy data.\n","2. Compute fractional deltas to several mathematical constants.\n","3. Cluster a chosen numeric column with DBSCAN or MeanShift.\n","4. (Optionally) detect new values vs a previous results CSV.\n","5. Export a clean CSV of results.\n","\n","Everything runs locally inside Colab—no external drives or prior chats needed."]},{"cell_type":"code","execution_count":null,"id":"7945113d","metadata":{"id":"7945113d"},"outputs":[],"source":["\n","# ============== CONFIGURATION ==============\n","# Set these before running the pipeline.\n","NUM_COL        = 'slice'   # numeric column to analyse\n","CLUST_METRIC   = 'euclidean'   # 'euclidean', 'manhattan', 'cosine', ...\n","BANDWIDTH      = 0.001     # ε / bandwidth for clustering\n","EXPORT_NAME    = 'autoscan_results.csv'\n","# To diff against an earlier run, put its CSV filename here (or None)\n","PREVIOUS_CSV   = None\n","NEW_THRESHOLD  = 1e-12\n","# ===========================================\n"]},{"cell_type":"code","execution_count":null,"id":"d880cf62","metadata":{"id":"d880cf62"},"outputs":[],"source":["\n","import pandas as pd\n","import numpy as np\n","from google.colab import files\n","from pathlib import Path\n","import io, os\n","\n","def choose_data():\n","    \"\"\"Return raw_df, ops_df after user upload or dummy generation.\"\"\"\n","    print('▶ Upload two Excel files (raw & ops). If you skip, dummy data will be used.')\n","    uploaded = files.upload()\n","    excel_paths = []\n","    for name in uploaded.keys():\n","        if name.endswith('.xlsx'):\n","            excel_paths.append(name)\n","    if len(excel_paths) >= 2:\n","        raw_df = pd.read_excel(excel_paths[0])\n","        ops_df = pd.read_excel(excel_paths[1])\n","        print(f'✔ Loaded {excel_paths[0]} and {excel_paths[1]}')\n","    else:\n","        # Dummy fallback\n","        x = np.linspace(0.0005, 0.015, 200)\n","        raw_df = pd.DataFrame({'dummy': x})\n","        ops_df = pd.DataFrame({'slice': x + np.random.normal(0, 1e-4, len(x))})\n","        print('⚠ Using autogenerated dummy data (200 values).')\n","    return raw_df, ops_df\n","\n","raw_df, ops_df = choose_data()\n","raw_df.head(), ops_df.head()\n"]},{"cell_type":"code","execution_count":null,"id":"2358ffa8","metadata":{"id":"2358ffa8"},"outputs":[],"source":["\n","# Mathematical constants\n","import numpy as np\n","\n","CONST = {\n","    'alpha_inv': 137.035999084,\n","    'phi'      : (1 + 5**0.5) / 2,\n","    'sqrt2'    : 2**0.5,\n","    'e'        : np.e,\n","}\n","\n","def delta(x, ref): return abs(x - ref) / ref\n","\n","for name, ref in CONST.items():\n","    ops_df[f'delta_{name}'] = ops_df[NUM_COL].apply(lambda v: delta(v, ref))\n","\n","ops_df.head()\n"]},{"cell_type":"code","execution_count":null,"id":"507ed551","metadata":{"id":"507ed551"},"outputs":[],"source":["\n","from sklearn.cluster import DBSCAN, MeanShift\n","vals = ops_df[[NUM_COL]].values\n","\n","if CLUST_METRIC in {'euclidean', 'manhattan'}:\n","    model = DBSCAN(eps=BANDWIDTH, metric=CLUST_METRIC, min_samples=2).fit(vals)\n","else:\n","    model = MeanShift(bandwidth=BANDWIDTH).fit(vals)\n","\n","ops_df['cluster'] = model.labels_\n","print('Cluster counts:\\n', ops_df['cluster'].value_counts())\n"]},{"cell_type":"code","execution_count":null,"id":"2df1050e","metadata":{"id":"2df1050e"},"outputs":[],"source":["\n","import pandas as pd, numpy as np, os\n","new_entries = pd.DataFrame()\n","\n","if PREVIOUS_CSV and Path(PREVIOUS_CSV).exists():\n","    prev_df = pd.read_csv(PREVIOUS_CSV)\n","    prev_vals = set(np.round(prev_df[NUM_COL], 12))\n","    curr_vals = set(np.round(ops_df[NUM_COL], 12))\n","    diff_vals = [v for v in curr_vals if all(abs(v - pv) > NEW_THRESHOLD for pv in prev_vals)]\n","    new_entries = ops_df[np.isin(np.round(ops_df[NUM_COL], 12), diff_vals)]\n","    print(f'▲ {len(new_entries)} new values compared to {PREVIOUS_CSV}')\n","else:\n","    print('Diff step skipped (no previous CSV provided).')\n"]},{"cell_type":"code","execution_count":null,"id":"0e6a8c2b","metadata":{"id":"0e6a8c2b"},"outputs":[],"source":["\n","import matplotlib.pyplot as plt\n","plt.figure(figsize=(10,5))\n","plt.scatter(ops_df.index, ops_df[NUM_COL], c=ops_df['cluster'])\n","plt.title('Clustered values')\n","plt.xlabel('Index'); plt.ylabel(NUM_COL)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"2edb58fb","metadata":{"id":"2edb58fb"},"outputs":[],"source":["\n","ops_df.to_csv(EXPORT_NAME, index=False)\n","print(f'✔ Results saved to {EXPORT_NAME}')\n","if not new_entries.empty:\n","    new_name = 'new_entries_' + EXPORT_NAME\n","    new_entries.to_csv(new_name, index=False)\n","    print(f'✔ New entries saved to {new_name}')\n"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}